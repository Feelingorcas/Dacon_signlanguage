{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SignLanguage.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNIB1nDexrSmMT18dPyLvLq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a2c5a8ae217a44b3bd6f4e51eb6c1418": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d85dc8f1e3064466a961013cecda5dd1",
              "IPY_MODEL_347315eff05c4f6388e8c56e1dbb1605",
              "IPY_MODEL_71fe477487fc49728938bae5e8d17937"
            ],
            "layout": "IPY_MODEL_58d6e2ff11884700a1fb0e2ca23a3f5f"
          }
        },
        "d85dc8f1e3064466a961013cecda5dd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d7866ccff634aa6a1b6a26ac49678c3",
            "placeholder": "​",
            "style": "IPY_MODEL_0b002512c51b4477a5749bfea636d727",
            "value": "100%"
          }
        },
        "347315eff05c4f6388e8c56e1dbb1605": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e262edb53d944380a3e9d22803b1f426",
            "max": 7,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_14b7c1b4faae45a3919c7c8e7e360628",
            "value": 7
          }
        },
        "71fe477487fc49728938bae5e8d17937": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_771289b4cff147a395472ed67de5c6fd",
            "placeholder": "​",
            "style": "IPY_MODEL_32e44cd894894f2b9b6f802195025341",
            "value": " 7/7 [00:03&lt;00:00,  2.76it/s]"
          }
        },
        "58d6e2ff11884700a1fb0e2ca23a3f5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d7866ccff634aa6a1b6a26ac49678c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b002512c51b4477a5749bfea636d727": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e262edb53d944380a3e9d22803b1f426": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14b7c1b4faae45a3919c7c8e7e360628": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "771289b4cff147a395472ed67de5c6fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32e44cd894894f2b9b6f802195025341": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Feelingorcas/Dacon_signlanguage/blob/main/SignLanguage.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRwiUOjpOWZr",
        "outputId": "c0e4967f-c7be-4c27-846f-6a1bdcba028c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#Dacon 수화 이미지 classification task 진행 시작 5월 23일 23시 02분 \n",
        "\n",
        "#목표 - 정확도 0.97 이상을 원함 - 성취 sota model 사용해보기- sota 모델보다는 새로운 모델을 사용하는것을 DLA 사용함.\n",
        "\n",
        "\n",
        "#https://dacon.io/competitions/official/235896/overview/description\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount = True)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Libraries \n",
        "import torch \n",
        "import tensorflow as tf\n",
        "import torch.nn as nn\n",
        "import pandas as pd \n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt \n",
        "import os \n",
        "import random\n",
        "import torchvision.datasets as datasets \n",
        "import torchvision.transforms as transforms \n"
      ],
      "metadata": {
        "id": "ZrmybcRcO0w2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU \n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mpX2RDQsO8nR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameters tuning \n",
        "\n",
        "CFG = {\n",
        "    'IMG_SIZE':256, #이미지 사이즈\n",
        "    'EPOCHS':50, #에포크\n",
        "    'LR':0.1, #학습률\n",
        "    'BATCH_SIZE':32, #배치사이즈\n",
        "    'SEED':10018,\n",
        "    'Directory' : '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/'\n",
        "}"
      ],
      "metadata": {
        "id": "AJuACNDSPPQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# 대회 pipeline 코드에서 따온건데 모델 재현성 한번에! \n",
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "seed_everything(CFG['SEED'])"
      ],
      "metadata": {
        "id": "ph5xu7sLPdDW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell \n",
        "cd /content/drive/MyDrive/Kaggles/Dacon_SignLanguage\n",
        "mkdir /content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data\n",
        "unzip user_data.zip -d /content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data\n",
        "cd /content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data\n",
        "ls"
      ],
      "metadata": {
        "id": "_8klnfJKPxs6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a734a8cf-f065-4934-d662-e323b7a8c3e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data’: File exists\n",
            "Archive:  user_data.zip\n",
            "replace /content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/sample_submission.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n",
            "sample_submission.csv  submit.csv  test  test.csv  train  train.csv\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datadir = '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/'\n",
        "\n",
        "\n",
        "traindf = pd.read_csv(datadir+ 'train.csv')\n",
        "testdf = pd.read_csv(datadir + 'test.csv')\n",
        "traindf.info()\n",
        "traindf['label'].value_counts()\n",
        "traindf['label'].describe()\n",
        "# plt.hist(traindf['label'])\n",
        "# plt.show()\n",
        "### 하다보니깐 데이터가 너무 부족함 augmentation이 필요해서 회전 좌우반전이랑 noise 넣어서 데이터 10~20배 정도 뻥튀기 시켜야겠다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFYs--tORddQ",
        "outputId": "935d50c2-7af0-4f03-bddd-4de2ee78dee6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 858 entries, 0 to 857\n",
            "Data columns (total 2 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   file_name  858 non-null    object\n",
            " 1   label      858 non-null    object\n",
            "dtypes: object(2)\n",
            "memory usage: 13.5+ KB\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count     858\n",
              "unique     11\n",
              "top         2\n",
              "freq       83\n",
              "Name: label, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "traindf['label'][traindf['label'] == '10-1'] = 10 ## label : 10-1 -> 10\n",
        "traindf['label'][traindf['label'] == '10-2'] = 0 ## Label : 10-2 -> 0\n",
        "traindf['label'] = traindf['label'].apply(lambda x : int(x)) ## Dtype : object -> int\n",
        "\n",
        "CFG['num_classes']= len(traindf['label'].unique())\n",
        "CFG['num_classes'] = CFG['num_classes']"
      ],
      "metadata": {
        "id": "BjUTodIITQE6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from glob import glob\n",
        "\n",
        "def get_train_data(data_dir):\n",
        "    img_path_list = []\n",
        "    label_list = []\n",
        "    \n",
        "    # get image path\n",
        "    img_path_list.extend(glob(os.path.join(data_dir, '*.png')))\n",
        "    img_path_list.sort(key=lambda x:int(x.split('/')[-1].split('.')[0])) # 순서대로 바꿔놓기 - data에 따라 다름.\n",
        "        \n",
        "    # get label\n",
        "    #label_df = pd.read_csv(data_dir+'/train.csv')\n",
        "    label_list.extend(traindf['label'])\n",
        "                \n",
        "    return img_path_list, label_list\n",
        "\n",
        "def get_test_data(data_dir):\n",
        "    img_path_list = []\n",
        "    \n",
        "    # get image path\n",
        "    img_path_list.extend(glob(os.path.join(data_dir, '*.png')))\n",
        "    img_path_list.sort(key=lambda x:int(x.split('/')[-1].split('.')[0]))\n",
        "\n",
        "    \n",
        "    return img_path_list"
      ],
      "metadata": {
        "id": "jwS7uXd7Us4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_img_path, train_label = get_train_data(datadir +'train')\n",
        "test_img_path = get_test_data(datadir +'test')\n",
        "\n",
        "\n",
        "print(train_img_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKC6cJ5kVCMg",
        "outputId": "d3e89a94-aba0-4d5c-8903-8c9868641812"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/001.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/002.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/003.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/004.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/005.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/006.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/007.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/008.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/009.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/010.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/011.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/012.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/013.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/014.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/015.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/016.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/017.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/018.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/019.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/020.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/021.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/022.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/023.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/024.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/025.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/026.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/027.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/028.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/029.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/030.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/031.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/032.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/033.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/034.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/035.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/036.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/037.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/038.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/039.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/040.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/041.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/042.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/043.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/044.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/045.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/046.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/047.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/048.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/049.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/050.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/051.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/052.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/053.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/054.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/055.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/056.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/057.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/058.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/059.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/060.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/061.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/062.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/063.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/064.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/065.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/066.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/067.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/068.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/069.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/070.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/071.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/072.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/073.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/074.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/075.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/076.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/077.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/078.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/079.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/080.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/081.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/082.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/083.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/084.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/085.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/086.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/087.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/088.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/089.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/090.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/091.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/092.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/093.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/094.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/095.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/096.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/097.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/098.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/099.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/100.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/101.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/102.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/103.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/104.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/105.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/106.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/107.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/108.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/109.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/110.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/111.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/112.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/113.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/114.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/115.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/116.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/117.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/118.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/119.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/120.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/121.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/122.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/123.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/124.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/125.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/126.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/127.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/128.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/129.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/130.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/131.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/132.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/133.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/134.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/135.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/136.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/137.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/138.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/139.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/140.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/141.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/142.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/143.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/144.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/145.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/146.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/147.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/148.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/149.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/150.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/151.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/152.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/153.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/154.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/155.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/156.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/157.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/158.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/159.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/160.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/161.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/162.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/163.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/164.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/165.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/166.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/167.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/168.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/169.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/170.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/171.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/172.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/173.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/174.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/175.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/176.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/177.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/178.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/179.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/180.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/181.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/182.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/183.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/184.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/185.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/186.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/187.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/188.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/189.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/190.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/191.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/192.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/193.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/194.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/195.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/196.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/197.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/198.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/199.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/200.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/201.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/202.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/203.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/204.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/205.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/206.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/207.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/208.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/209.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/210.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/211.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/212.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/213.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/214.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/215.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/216.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/217.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/218.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/219.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/220.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/221.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/222.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/223.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/224.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/225.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/226.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/227.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/228.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/229.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/230.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/231.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/232.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/233.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/234.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/235.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/236.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/237.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/238.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/239.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/240.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/241.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/242.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/243.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/244.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/245.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/246.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/247.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/248.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/249.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/250.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/251.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/252.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/253.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/254.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/255.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/256.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/257.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/258.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/259.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/260.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/261.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/262.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/263.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/264.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/265.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/266.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/267.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/268.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/269.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/270.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/271.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/272.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/273.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/274.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/275.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/276.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/277.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/278.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/279.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/280.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/281.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/282.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/283.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/284.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/285.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/286.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/287.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/288.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/289.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/290.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/291.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/292.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/293.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/294.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/295.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/296.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/297.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/298.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/299.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/300.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/301.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/302.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/303.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/304.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/305.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/306.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/307.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/308.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/309.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/310.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/311.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/312.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/313.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/314.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/315.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/316.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/317.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/318.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/319.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/320.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/321.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/322.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/323.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/324.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/325.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/326.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/327.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/328.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/329.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/330.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/331.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/332.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/333.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/334.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/335.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/336.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/337.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/338.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/339.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/340.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/341.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/342.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/343.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/344.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/345.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/346.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/347.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/348.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/349.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/350.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/351.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/352.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/353.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/354.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/355.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/356.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/357.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/358.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/359.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/360.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/361.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/362.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/363.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/364.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/365.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/366.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/367.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/368.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/369.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/370.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/371.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/372.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/373.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/374.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/375.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/376.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/377.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/378.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/379.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/380.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/381.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/382.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/383.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/384.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/385.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/386.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/387.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/388.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/389.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/390.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/391.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/392.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/393.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/394.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/395.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/396.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/397.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/398.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/399.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/400.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/401.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/402.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/403.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/404.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/405.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/406.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/407.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/408.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/409.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/410.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/411.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/412.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/413.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/414.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/415.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/416.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/417.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/418.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/419.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/420.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/421.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/422.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/423.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/424.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/425.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/426.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/427.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/428.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/429.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/430.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/431.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/432.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/433.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/434.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/435.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/436.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/437.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/438.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/439.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/440.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/441.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/442.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/443.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/444.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/445.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/446.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/447.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/448.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/449.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/450.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/451.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/452.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/453.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/454.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/455.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/456.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/457.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/458.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/459.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/460.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/461.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/462.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/463.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/464.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/465.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/466.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/467.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/468.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/469.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/470.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/471.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/472.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/473.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/474.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/475.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/476.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/477.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/478.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/479.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/480.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/481.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/482.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/483.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/484.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/485.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/486.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/487.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/488.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/489.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/490.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/491.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/492.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/493.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/494.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/495.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/496.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/497.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/498.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/499.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/500.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/501.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/502.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/503.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/504.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/505.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/506.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/507.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/508.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/509.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/510.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/511.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/512.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/513.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/514.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/515.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/516.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/517.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/518.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/519.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/520.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/521.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/522.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/523.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/524.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/525.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/526.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/527.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/528.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/529.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/530.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/531.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/532.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/533.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/534.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/535.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/536.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/537.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/538.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/539.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/540.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/541.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/542.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/543.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/544.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/545.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/546.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/547.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/548.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/549.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/550.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/551.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/552.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/553.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/554.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/555.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/556.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/557.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/558.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/559.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/560.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/561.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/562.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/563.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/564.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/565.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/566.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/567.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/568.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/569.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/570.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/571.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/572.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/573.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/574.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/575.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/576.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/577.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/578.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/579.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/580.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/581.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/582.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/583.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/584.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/585.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/586.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/587.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/588.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/589.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/590.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/591.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/592.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/593.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/594.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/595.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/596.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/597.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/598.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/599.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/600.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/601.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/602.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/603.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/604.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/605.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/606.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/607.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/608.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/609.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/610.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/611.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/612.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/613.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/614.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/615.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/616.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/617.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/618.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/619.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/620.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/621.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/622.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/623.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/624.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/625.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/626.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/627.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/628.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/629.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/630.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/631.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/632.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/633.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/634.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/635.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/636.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/637.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/638.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/639.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/640.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/641.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/642.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/643.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/644.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/645.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/646.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/647.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/648.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/649.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/650.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/651.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/652.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/653.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/654.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/655.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/656.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/657.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/658.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/659.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/660.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/661.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/662.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/663.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/664.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/665.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/666.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/667.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/668.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/669.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/670.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/671.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/672.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/673.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/674.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/675.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/676.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/677.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/678.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/679.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/680.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/681.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/682.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/683.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/684.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/685.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/686.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/687.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/688.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/689.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/690.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/691.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/692.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/693.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/694.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/695.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/696.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/697.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/698.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/699.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/700.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/701.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/702.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/703.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/704.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/705.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/706.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/707.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/708.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/709.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/710.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/711.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/712.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/713.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/714.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/715.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/716.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/717.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/718.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/719.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/720.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/721.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/722.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/723.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/724.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/725.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/726.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/727.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/728.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/729.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/730.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/731.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/732.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/733.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/734.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/735.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/736.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/737.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/738.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/739.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/740.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/741.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/742.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/743.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/744.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/745.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/746.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/747.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/748.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/749.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/750.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/751.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/752.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/753.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/754.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/755.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/756.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/757.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/758.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/759.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/760.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/761.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/762.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/763.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/764.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/765.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/766.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/767.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/768.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/769.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/770.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/771.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/772.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/773.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/774.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/775.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/776.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/777.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/778.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/779.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/780.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/781.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/782.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/783.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/784.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/785.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/786.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/787.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/788.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/789.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/790.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/791.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/792.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/793.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/794.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/795.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/796.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/797.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/798.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/799.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/800.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/801.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/802.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/803.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/804.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/805.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/806.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/807.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/808.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/809.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/810.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/811.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/812.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/813.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/814.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/815.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/816.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/817.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/818.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/819.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/820.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/821.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/822.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/823.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/824.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/825.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/826.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/827.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/828.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/829.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/830.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/831.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/832.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/833.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/834.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/835.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/836.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/837.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/838.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/839.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/840.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/841.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/842.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/843.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/844.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/845.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/846.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/847.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/848.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/849.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/850.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/851.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/852.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/853.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/854.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/855.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/856.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/857.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/858.png']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader \n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "# Dataloader 써서 이제 dataloader 만들기\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, imgs , labels , mode = 'train'): #필요한 변수들을 선언      \n",
        "        self.imgs = imgs\n",
        "        self.labels = labels \n",
        "        self.mode = mode \n",
        "\n",
        "        \n",
        "    def __getitem__(self, index): #index번째 data를 return\n",
        "    \n",
        "        image = self.imgs[index]\n",
        "        # Get image data\n",
        "        \n",
        "        if self.mode != 'test':\n",
        "            label = self.labels[index]\n",
        "            return image, label\n",
        "        else:\n",
        "            return image\n",
        "    \n",
        "    def __len__(self): #길이 return\n",
        "        return len(self.imgs)"
      ],
      "metadata": {
        "id": "g3buiJCDYb0d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def augmentation(img_path,label_list,train = True ) : \n",
        "     imgs = []\n",
        "     labels  =  [] \n",
        "     augument_transform  = transforms.Compose([\n",
        "                    transforms.ToPILImage(), #Numpy배열에서 PIL이미지로\n",
        "                    transforms.Resize([CFG['IMG_SIZE'], CFG['IMG_SIZE']]), #이미지 사이즈 변형\n",
        "                    transforms.ToTensor(), #이미지 데이터를 tensor\n",
        "                    transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)) #이미지 정규화  \n",
        "                    ])\n",
        "\n",
        "     rotation = transforms.RandomRotation((-180,180)) \n",
        "     vertical_flip =transforms.RandomRotation((-180,180)) \n",
        "     horizontal_flip =transforms.RandomRotation((-180,180)) \n",
        "     \n",
        "\n",
        "     merges = (rotation, vertical_flip,horizontal_flip)\n",
        "     \n",
        "     for idx , img in enumerate(img_path ) :\n",
        "              \n",
        "              image_tensor = augument_transform(cv2.imread(img))\n",
        "              #print(image_tensor.shape)\n",
        "\n",
        "              imgs.append(image_tensor)\n",
        "              if label_list is not None :\n",
        "                  label = label_list[idx]\n",
        "                  labels.append(label)\n",
        "              if train : \n",
        "                for merge in merges : \n",
        "                   imgs.append(merge(image_tensor))\n",
        "\n",
        "                   if label_list is not None :\n",
        "                       label = label_list[idx]\n",
        "                       labels.append(label)\n",
        "\n",
        "     return  imgs, labels          "
      ],
      "metadata": {
        "id": "3x3nDQ4UjQOL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train : Validation = 0.8 : 0.2 Split random으로 하고 싶은데, \n",
        "train_len = int(len(train_img_path)*1)\n",
        "Vali_len = int(len(train_img_path)*0.5)\n",
        "\n",
        "vali_img_path = train_img_path[0:]\n",
        "vali_label = train_label[0::]\n",
        "\n",
        "\n",
        "train_img_path = train_img_path[:train_len]\n",
        "train_label = train_label[:train_len]\n",
        "\n",
        "print('train set 길이 : ', train_len)\n",
        "print('vaildation set 길이 : ', Vali_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gO03ujOvYvMj",
        "outputId": "9c88a58d-40ac-40a6-a71d-aa5f33c012d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train set 길이 :  858\n",
            "vaildation set 길이 :  429\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(vali_img_path[:10])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wQQFc2JasmL",
        "outputId": "dd56b9de-e807-4ad2-e099-107be9e0ec2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/773.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/774.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/775.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/776.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/777.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/778.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/779.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/780.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/781.png', '/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/data/train/782.png']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train_transform = transforms.Compose([\n",
        "#                     transforms.ToPILImage(), #Numpy배열에서 PIL이미지로\n",
        "#                     transforms.Resize([CFG['IMG_SIZE'], CFG['IMG_SIZE']]), #이미지 사이즈 변형\n",
        "#                     transforms.ToTensor(), #이미지 데이터를 tensor\n",
        "#                     transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)) #이미지 정규화  \n",
        "#                     ])\n",
        "\n",
        "# test_transform = transforms.Compose([\n",
        "#                     transforms.ToPILImage(),\n",
        "#                     transforms.Resize([CFG['IMG_SIZE'], CFG['IMG_SIZE']]),\n",
        "#                     transforms.ToTensor(),\n",
        "#                     transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
        "#                     ])\n",
        "\n",
        "\n",
        "\n",
        "# Get Dataloader\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#CustomDataset class를 통하여 train dataset생성\n",
        "train_imgs , train_labels = augmentation(train_img_path,train_label,train = True) # train 이면 augmentation valid 면 안함.\n",
        "train_dataset = CustomDataset(train_imgs,  train_labels, mode='train') \n",
        "train_loader = DataLoader(train_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=True, num_workers=4) #BATCH_SIZE : 24\n",
        "\n",
        "#vaildation 에서도 적용\n",
        "valid_imgs , valid_labels = augmentation(vali_img_path, vali_label,train = False) \n",
        "vali_dataset = CustomDataset(valid_imgs,valid_labels, mode = 'valid')\n",
        "vali_loader = DataLoader(vali_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=False, num_workers=4)"
      ],
      "metadata": {
        "id": "C5XmcI3SZnfp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_batches = len(train_loader)\n",
        "vali_batches = len(vali_loader)\n",
        "\n",
        "print('total train imgs :',train_batches*CFG['BATCH_SIZE'],'/ total train batches :', train_batches) # 마지막 batch는 작으니깐.\n",
        "print('total valid imgs :',vali_batches*CFG['BATCH_SIZE'], '/ total valid batches :', vali_batches)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJVv5HnraD3a",
        "outputId": "efbf2454-1150-47b1-feef-fd72250ee1cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total train imgs : 3456 / total train batches : 108\n",
            "total valid imgs : 864 / total valid batches : 27\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "train_features, train_labels = next(iter(train_loader))\n",
        "\n",
        "print(train_features.shape)\n",
        "                 \n",
        "img = train_features[0] # 각 batch의 첫번째 img \n",
        "label = train_labels[0]\n",
        "plt.imshow(img[0], cmap=\"gray\")\n",
        "plt.show()\n",
        "print(f\"Label: {label}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "id": "d7iJYl1ubJtU",
        "outputId": "25ceddf8-e6a3-4a32-88a5-0161b7c2211b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 3, 256, 256])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "GT2W-p5MDas0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "3McgW2DrDeKt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 전처리는 빠르게 진행하기 위해 pipe line의 대부분을 따왔고 일부 train valid set 나누는 거나, 그런건 수정을 하였음.\n",
        "# resnet 이나 VGG 등등을 활용하는 게 나을 듯 전이학습으로. #CNN 모델 하나 Transformer 기반 모델 하나  \n",
        "## model \n",
        "\n",
        "\n",
        "## CNN 모델 DLA를 들고왔음 # official한 곳에서 -> Resnet, efficientnet은 IAB challenge하면서 많이봐서, 새롭게 DLA 라는 모델을 데리고옴. sota는 아니지만 Model soup technique가 imagenet 3위? 4위이라\n",
        "## 구현하고 싶었으나, 실패하고 링크를 타고 타다가 발견함\n",
        "\n",
        "import math\n",
        "from os.path import join\n",
        "from torch import nn\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "!pip install dataset\n",
        "import dataset\n",
        "\n",
        "\n",
        "BatchNorm = nn.BatchNorm2d\n",
        "\n",
        "WEB_ROOT = 'http://dl.yf.io/dla/models'\n",
        "\n",
        "\n",
        "def get_model_url(data, name):\n",
        "    return join(WEB_ROOT, data.name,\n",
        "                '{}-{}.pth'.format(name, data.model_hash[name]))\n",
        "\n",
        "\n",
        "\n",
        "## 이렇게 stride를 1짜리를 쓸거면 아예 함수로 def해놓고 사용하는 것도 나쁘지 않을 듯 나는 class 가 11개이니깐 architecture을 조금은 수정해야겠네\n",
        "\n",
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    \"3x3 convolution with padding\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=1, bias=False)\n",
        "\n",
        "\n",
        "\n",
        "## conv block 이 모여 stage \n",
        "class BasicBlock(nn.Module):\n",
        "    def __init__(self, inplanes, planes, stride=1, dilation=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=3,\n",
        "                               stride=stride, padding=dilation,\n",
        "                               bias=False, dilation=dilation)\n",
        "        self.bn1 = BatchNorm(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               stride=1, padding=dilation,\n",
        "                               bias=False, dilation=dilation)\n",
        "        self.bn2 = BatchNorm(planes)\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x, residual=None):\n",
        "        if residual is None:\n",
        "            residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "# bottleneck block \n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 2\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, dilation=1):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        expansion = Bottleneck.expansion\n",
        "        bottle_planes = planes // expansion\n",
        "        self.conv1 = nn.Conv2d(inplanes, bottle_planes,\n",
        "                               kernel_size=1, bias=False)\n",
        "        self.bn1 = BatchNorm(bottle_planes)\n",
        "        self.conv2 = nn.Conv2d(bottle_planes, bottle_planes, kernel_size=3,\n",
        "                               stride=stride, padding=dilation,\n",
        "                               bias=False, dilation=dilation)\n",
        "        self.bn2 = BatchNorm(bottle_planes)\n",
        "        self.conv3 = nn.Conv2d(bottle_planes, planes,\n",
        "                               kernel_size=1, bias=False)\n",
        "        self.bn3 = BatchNorm(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x, residual=None):\n",
        "        if residual is None:\n",
        "            residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "# bottlenet인데 뭔지 정확히는 모르겠음 -> 논문보고 알아내야지\n",
        "class BottleneckX(nn.Module):\n",
        "    expansion = 2\n",
        "    cardinality = 32\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, dilation=1):\n",
        "        super(BottleneckX, self).__init__()\n",
        "        cardinality = BottleneckX.cardinality\n",
        "        # dim = int(math.floor(planes * (BottleneckV5.expansion / 64.0)))\n",
        "        # bottle_planes = dim * cardinality\n",
        "        bottle_planes = planes * cardinality // 32\n",
        "        self.conv1 = nn.Conv2d(inplanes, bottle_planes,\n",
        "                               kernel_size=1, bias=False)\n",
        "        self.bn1 = BatchNorm(bottle_planes)\n",
        "        self.conv2 = nn.Conv2d(bottle_planes, bottle_planes, kernel_size=3,\n",
        "                               stride=stride, padding=dilation, bias=False,\n",
        "                               dilation=dilation, groups=cardinality)\n",
        "        self.bn2 = BatchNorm(bottle_planes)\n",
        "        self.conv3 = nn.Conv2d(bottle_planes, planes,\n",
        "                               kernel_size=1, bias=False)\n",
        "        self.bn3 = BatchNorm(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x, residual=None):\n",
        "        if residual is None:\n",
        "            residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "#residual을 사용하는 걸 봐선 resnet과 유사한데.. why root?\n",
        "class Root(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, residual):\n",
        "        super(Root, self).__init__()\n",
        "        self.conv = nn.Conv2d(\n",
        "            in_channels, out_channels, kernel_size,\n",
        "            stride=1, bias=False, padding=(kernel_size - 1) // 2)\n",
        "        self.bn = BatchNorm(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.residual = residual\n",
        "\n",
        "    def forward(self, *x):\n",
        "        children = x\n",
        "        x = self.conv(torch.cat(x, 1))\n",
        "        x = self.bn(x)\n",
        "        if self.residual:\n",
        "            x += children[0]\n",
        "        x = self.relu(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class Tree(nn.Module):\n",
        "    def __init__(self, levels, block, in_channels, out_channels, stride=1,\n",
        "                 level_root=False, root_dim=0, root_kernel_size=1,\n",
        "                 dilation=1, root_residual=False):\n",
        "        super(Tree, self).__init__()\n",
        "        if root_dim == 0:\n",
        "            root_dim = 2 * out_channels\n",
        "        if level_root:\n",
        "            root_dim += in_channels\n",
        "        if levels == 1:\n",
        "            self.tree1 = block(in_channels, out_channels, stride,\n",
        "                               dilation=dilation)\n",
        "            self.tree2 = block(out_channels, out_channels, 1,\n",
        "                               dilation=dilation)\n",
        "        else:\n",
        "            self.tree1 = Tree(levels - 1, block, in_channels, out_channels,\n",
        "                              stride, root_dim=0,\n",
        "                              root_kernel_size=root_kernel_size,\n",
        "                              dilation=dilation, root_residual=root_residual)\n",
        "            self.tree2 = Tree(levels - 1, block, out_channels, out_channels,\n",
        "                              root_dim=root_dim + out_channels,\n",
        "                              root_kernel_size=root_kernel_size,\n",
        "                              dilation=dilation, root_residual=root_residual)\n",
        "        if levels == 1:\n",
        "            self.root = Root(root_dim, out_channels, root_kernel_size,\n",
        "                             root_residual)\n",
        "        self.level_root = level_root\n",
        "        self.root_dim = root_dim\n",
        "        self.downsample = None\n",
        "        self.project = None\n",
        "        self.levels = levels\n",
        "        if stride > 1:\n",
        "            self.downsample = nn.MaxPool2d(stride, stride=stride)\n",
        "        if in_channels != out_channels:\n",
        "            self.project = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels,\n",
        "                          kernel_size=1, stride=1, bias=False),\n",
        "                BatchNorm(out_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x, residual=None, children=None):\n",
        "        children = [] if children is None else children\n",
        "        bottom = self.downsample(x) if self.downsample else x\n",
        "        residual = self.project(bottom) if self.project else bottom\n",
        "        if self.level_root:\n",
        "            children.append(bottom)\n",
        "        x1 = self.tree1(x, residual)\n",
        "        if self.levels == 1:\n",
        "            x2 = self.tree2(x1)\n",
        "            x = self.root(x2, x1, *children)\n",
        "        else:\n",
        "            children.append(x1)\n",
        "            x = self.tree2(x1, children=children)\n",
        "        return x\n",
        "\n",
        "\n",
        "# full model architecture / resnet과 달리 HDA, IDA라는 구조가 있음 - 논문리뷰할 예정\n",
        "class DLA(nn.Module):\n",
        "    def __init__(self, levels, channels, num_classes=1000,\n",
        "                 block=BasicBlock, residual_root=False, return_levels=False,\n",
        "                 pool_size=7, linear_root=False):\n",
        "        super(DLA, self).__init__()\n",
        "        self.channels = channels\n",
        "        self.return_levels = return_levels\n",
        "        self.num_classes = num_classes\n",
        "        self.base_layer = nn.Sequential(\n",
        "            nn.Conv2d(3, channels[0], kernel_size=7, stride=1,\n",
        "                      padding=3, bias=False),\n",
        "            BatchNorm(channels[0]),\n",
        "            nn.ReLU(inplace=True))\n",
        "        self.level0 = self._make_conv_level(\n",
        "            channels[0], channels[0], levels[0])\n",
        "        self.level1 = self._make_conv_level(\n",
        "            channels[0], channels[1], levels[1], stride=2)\n",
        "        self.level2 = Tree(levels[2], block, channels[1], channels[2], 2,\n",
        "                           level_root=False,\n",
        "                           root_residual=residual_root)\n",
        "        self.level3 = Tree(levels[3], block, channels[2], channels[3], 2,\n",
        "                           level_root=True, root_residual=residual_root)\n",
        "        self.level4 = Tree(levels[4], block, channels[3], channels[4], 2,\n",
        "                           level_root=True, root_residual=residual_root)\n",
        "        self.level5 = Tree(levels[5], block, channels[4], channels[5], 2,\n",
        "                           level_root=True, root_residual=residual_root)\n",
        "\n",
        "        self.avgpool = nn.AvgPool2d(pool_size)\n",
        "        self.fc = nn.Conv2d(channels[-1], num_classes, kernel_size=1,\n",
        "                            stride=1, padding=0, bias=True)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "            elif isinstance(m, BatchNorm):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def _make_level(self, block, inplanes, planes, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or inplanes != planes:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.MaxPool2d(stride, stride=stride),\n",
        "                nn.Conv2d(inplanes, planes,\n",
        "                          kernel_size=1, stride=1, bias=False),\n",
        "                BatchNorm(planes),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(inplanes, planes, stride, downsample=downsample))\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(inplanes, planes))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def _make_conv_level(self, inplanes, planes, convs, stride=1, dilation=1):\n",
        "        modules = []\n",
        "        for i in range(convs):\n",
        "            modules.extend([\n",
        "                nn.Conv2d(inplanes, planes, kernel_size=3,\n",
        "                          stride=stride if i == 0 else 1,\n",
        "                          padding=dilation, bias=False, dilation=dilation),\n",
        "                BatchNorm(planes),\n",
        "                nn.ReLU(inplace=True)])\n",
        "            inplanes = planes\n",
        "        return nn.Sequential(*modules)\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = []\n",
        "        x = self.base_layer(x)\n",
        "        for i in range(6):\n",
        "            x = getattr(self, 'level{}'.format(i))(x) #파이썬 내장함수\n",
        "            y.append(x)\n",
        "        if self.return_levels:\n",
        "            return y\n",
        "        else:\n",
        "            x = self.avgpool(x)\n",
        "            x = self.fc(x)\n",
        "            \n",
        "            x = x.view(x.size(0), -1) ## flatten으로 어차피 만들어줘서 fc layer없이 classifier 역할을 해줌 \n",
        "\n",
        "            return x\n",
        "\n",
        "    # 전이학습을 위한 pretrained model \n",
        "    def load_pretrained_model(self, data_name, name):\n",
        "        assert data_name in dataset.__dict__, \\\n",
        "            'No pretrained model for {}'.format(data_name)\n",
        "        data = dataset.__dict__[data_name]\n",
        "        fc = self.fc\n",
        "        if self.num_classes != data.classes:\n",
        "            self.fc = nn.Conv2d(\n",
        "                self.channels[-1], data.classes,\n",
        "                kernel_size=1, stride=1, padding=0, bias=True)\n",
        "        try:\n",
        "            model_url = get_model_url(data, name)\n",
        "        except KeyError:\n",
        "            raise ValueError(\n",
        "                '{} trained on {} does not exist.'.format(data.name, name))\n",
        "        self.load_state_dict(model_zoo.load_url(model_url))\n",
        "        self.fc = fc\n",
        "\n",
        "\n",
        "def dla34(pretrained=None, **kwargs):  # DLA-34\n",
        "    model = DLA([1, 1, 1, 2, 2, 1],\n",
        "                [16, 32, 64, 128, 256, 512],\n",
        "                block=BasicBlock, **kwargs)\n",
        "    if pretrained is not None:\n",
        "        model.load_pretrained_model(pretrained, 'dla34')\n",
        "    return model\n",
        "\n",
        "\n",
        "def dla46_c(pretrained=None, **kwargs):  # DLA-46-C\n",
        "    Bottleneck.expansion = 2\n",
        "    model = DLA([1, 1, 1, 2, 2, 1],\n",
        "                [16, 32, 64, 64, 128, 256],\n",
        "                block=Bottleneck, **kwargs)\n",
        "    if pretrained is not None:\n",
        "        model.load_pretrained_model(pretrained, 'dla46_c')\n",
        "    return model\n",
        "\n",
        "\n",
        "def dla46x_c(pretrained=None, **kwargs):  # DLA-X-46-C\n",
        "    BottleneckX.expansion = 2\n",
        "    model = DLA([1, 1, 1, 2, 2, 1],\n",
        "                [16, 32, 64, 64, 128, 256],\n",
        "                block=BottleneckX, **kwargs)\n",
        "    if pretrained is not None:\n",
        "        model.load_pretrained_model(pretrained, 'dla46x_c')\n",
        "    return model\n",
        "\n",
        "\n",
        "def dla60x_c(pretrained=None, **kwargs):  # DLA-X-60-C\n",
        "    BottleneckX.expansion = 2\n",
        "    model = DLA([1, 1, 1, 2, 3, 1],\n",
        "                [16, 32, 64, 64, 128, 256],\n",
        "                block=BottleneckX, **kwargs)\n",
        "    if pretrained is not None:\n",
        "        model.load_pretrained_model(pretrained, 'dla60x_c')\n",
        "    return model\n",
        "\n",
        "\n",
        "def dla60(pretrained=None, **kwargs):  # DLA-60\n",
        "    Bottleneck.expansion = 2\n",
        "    model = DLA([1, 1, 1, 2, 3, 1],\n",
        "                [16, 32, 128, 256, 512, 1024],\n",
        "                block=Bottleneck, **kwargs)\n",
        "    if pretrained is not None:\n",
        "        model.load_pretrained_model(pretrained, 'dla60')\n",
        "    return model\n",
        "\n",
        "\n",
        "def dla60x(pretrained=None, **kwargs):  # DLA-X-60\n",
        "    BottleneckX.expansion = 2\n",
        "    model = DLA([1, 1, 1, 2, 3, 1],\n",
        "                [16, 32, 128, 256, 512, 1024],\n",
        "                block=BottleneckX, **kwargs)\n",
        "    if pretrained is not None:\n",
        "        model.load_pretrained_model(pretrained, 'dla60x')\n",
        "    return model\n",
        "\n",
        "\n",
        "def dla102(pretrained=None, **kwargs):  # DLA-102\n",
        "    Bottleneck.expansion = 2\n",
        "    model = DLA([1, 1, 1, 3, 4, 1], [16, 32, 128, 256, 512, 1024],\n",
        "                block=Bottleneck, residual_root=True, **kwargs)\n",
        "    if pretrained is not None:\n",
        "        model.load_pretrained_model(pretrained, 'dla102')\n",
        "    return model\n",
        "\n",
        "\n",
        "def dla102x(pretrained=None, **kwargs):  # DLA-X-102\n",
        "    BottleneckX.expansion = 2\n",
        "    model = DLA([1, 1, 1, 3, 4, 1], [16, 32, 128, 256, 512, 1024],\n",
        "                block=BottleneckX, residual_root=True, **kwargs)\n",
        "    if pretrained is not None:\n",
        "        model.load_pretrained_model(pretrained, 'dla102x')\n",
        "    return model\n",
        "\n",
        "\n",
        "def dla102x2(pretrained=None, **kwargs):  # DLA-X-102 64\n",
        "    BottleneckX.cardinality = 64\n",
        "    model = DLA([1, 1, 1, 3, 4, 1], [16, 32, 128, 256, 512, 1024],\n",
        "                block=BottleneckX, residual_root=True, **kwargs)\n",
        "    if pretrained is not None:\n",
        "        model.load_pretrained_model(pretrained, 'dla102x2')\n",
        "    return model\n",
        "\n",
        "\n",
        "def dla169(pretrained=None, **kwargs):  # DLA-169\n",
        "    Bottleneck.expansion = 2\n",
        "    model = DLA([1, 1, 2, 3, 5, 1], [16, 32, 128, 256, 512, 1024],\n",
        "                block=Bottleneck, residual_root=True, **kwargs)\n",
        "    if pretrained is not None:\n",
        "        model.load_pretrained_model(pretrained, 'dla169')\n",
        "    return model\n",
        "\n"
      ],
      "metadata": {
        "id": "uCzJyb4Ebtue",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73277a05-530a-4114-ab2d-7a7e803b00e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: dataset in /usr/local/lib/python3.7/dist-packages (1.5.2)\n",
            "Requirement already satisfied: banal>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from dataset) (1.0.6)\n",
            "Requirement already satisfied: alembic>=0.6.2 in /usr/local/lib/python3.7/dist-packages (from dataset) (1.7.7)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.2 in /usr/local/lib/python3.7/dist-packages (from dataset) (1.4.36)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from alembic>=0.6.2->dataset) (4.11.3)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.7/dist-packages (from alembic>=0.6.2->dataset) (1.2.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic>=0.6.2->dataset) (5.7.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.3.2->dataset) (1.1.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->alembic>=0.6.2->dataset) (4.2.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->alembic>=0.6.2->dataset) (3.8.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic>=0.6.2->dataset) (2.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#전이학습을 위해 간단하게 만듦\n",
        "\n",
        "class Mymodel(nn.Module) :\n",
        "  def __init__(self,pretrained_model = None): \n",
        "    super(Mymodel,self).__init__()  \n",
        "    \n",
        "    self.DLA = dla102x2()\n",
        "    self.DLA.load_state_dict(torch.load('/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/pretrained/dla102x2-262837b6.pth'))\n",
        "    self.fc1 = nn.Linear(1000,11)\n",
        "    #self.fc2 = nn.Linear(256,CFG['num_classes'])\n",
        "\n",
        "\n",
        "  def forward(self, x) : \n",
        "      x = self.DLA(x)\n",
        "      x = self.fc1(x)\n",
        "      return x"
      ],
      "metadata": {
        "id": "PPdPqoGbnQmA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trainig"
      ],
      "metadata": {
        "id": "GSq4kV6jDgcy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## 전이학습 - class 개수가 엄청 작아져서 마지막 classifier만 따로 만들자 위에 굳이 굳이 다 구현되어있지만, dataset package가 뭔지 정확히 모르겠음 - > 빠른 진행을 위해 코드 자체적으로 짜서 ㄱ\n",
        "\n",
        "\n",
        "mymodel  = Mymodel() # class 1000 인 imagenet에 맞춤\n",
        "#mymodel.load_state_dict(torch.load('/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/pretrained/dla102x2-262837b6.pth'))\n",
        "\n",
        "\n",
        "for parameter in mymodel.parameters():\n",
        "     parameter.requires_grad = False\n",
        "\n",
        "for name, parameter in mymodel.named_parameters() : \n",
        "  if 'DLA.level5' in name or 'DLA.level4' in name  :\n",
        "        parameter.requires_grad = True \n",
        "\n",
        "mymodel.DLA.fc.weight.requires_grad =  True\n",
        "mymodel.DLA.fc.bias.requires_grad  = True     \n",
        "mymodel.fc1.weight.requires_grad = True \n",
        "mymodel.fc1.bias.requires_grad = True \n",
        "\n",
        "\n",
        "# mymodel.fc.weight.requires_grad = True \n",
        "mymodel.to(device)\n",
        "\n",
        "#mymodel = torch.nn.DataParallel(mymodel)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eoc3-0yr3IVY",
        "outputId": "318dc005-02b4-40e3-ab42-09d5e977bd71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Mymodel(\n",
              "  (DLA): DLA(\n",
              "    (base_layer): Sequential(\n",
              "      (0): Conv2d(3, 16, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
              "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "    )\n",
              "    (level0): Sequential(\n",
              "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "    )\n",
              "    (level1): Sequential(\n",
              "      (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "    )\n",
              "    (level2): Tree(\n",
              "      (tree1): BottleneckX(\n",
              "        (conv1): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (tree2): BottleneckX(\n",
              "        (conv1): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (root): Root(\n",
              "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (downsample): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (project): Sequential(\n",
              "        (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (level3): Tree(\n",
              "      (tree1): Tree(\n",
              "        (tree1): Tree(\n",
              "          (tree1): BottleneckX(\n",
              "            (conv1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
              "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (conv3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (tree2): BottleneckX(\n",
              "            (conv1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
              "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (conv3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (root): Root(\n",
              "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (downsample): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "          (project): Sequential(\n",
              "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (tree2): Tree(\n",
              "          (tree1): BottleneckX(\n",
              "            (conv1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
              "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (conv3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (tree2): BottleneckX(\n",
              "            (conv1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
              "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (conv3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (root): Root(\n",
              "            (conv): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "        )\n",
              "        (downsample): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "        (project): Sequential(\n",
              "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (tree2): Tree(\n",
              "        (tree1): Tree(\n",
              "          (tree1): BottleneckX(\n",
              "            (conv1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
              "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (conv3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (tree2): BottleneckX(\n",
              "            (conv1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
              "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (conv3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (root): Root(\n",
              "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "        )\n",
              "        (tree2): Tree(\n",
              "          (tree1): BottleneckX(\n",
              "            (conv1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
              "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (conv3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (tree2): BottleneckX(\n",
              "            (conv1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
              "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (conv3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (root): Root(\n",
              "            (conv): Conv2d(1152, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (downsample): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (project): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (level4): Tree(\n",
              "      (tree1): Tree(\n",
              "        (tree1): Tree(\n",
              "          (tree1): Tree(\n",
              "            (tree1): BottleneckX(\n",
              "              (conv1): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
              "              (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (conv3): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (relu): ReLU(inplace=True)\n",
              "            )\n",
              "            (tree2): BottleneckX(\n",
              "              (conv1): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
              "              (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (conv3): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (relu): ReLU(inplace=True)\n",
              "            )\n",
              "            (root): Root(\n",
              "              (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (relu): ReLU(inplace=True)\n",
              "            )\n",
              "            (downsample): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "            (project): Sequential(\n",
              "              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (tree2): Tree(\n",
              "            (tree1): BottleneckX(\n",
              "              (conv1): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
              "              (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (conv3): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (relu): ReLU(inplace=True)\n",
              "            )\n",
              "            (tree2): BottleneckX(\n",
              "              (conv1): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
              "              (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (conv3): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (relu): ReLU(inplace=True)\n",
              "            )\n",
              "            (root): Root(\n",
              "              (conv): Conv2d(1536, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (relu): ReLU(inplace=True)\n",
              "            )\n",
              "          )\n",
              "          (downsample): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "          (project): Sequential(\n",
              "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (tree2): Tree(\n",
              "          (tree1): Tree(\n",
              "            (tree1): BottleneckX(\n",
              "              (conv1): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
              "              (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (conv3): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (relu): ReLU(inplace=True)\n",
              "            )\n",
              "            (tree2): BottleneckX(\n",
              "              (conv1): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
              "              (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (conv3): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (relu): ReLU(inplace=True)\n",
              "            )\n",
              "            (root): Root(\n",
              "              (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (relu): ReLU(inplace=True)\n",
              "            )\n",
              "          )\n",
              "          (tree2): Tree(\n",
              "            (tree1): BottleneckX(\n",
              "              (conv1): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
              "              (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (conv3): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (relu): ReLU(inplace=True)\n",
              "            )\n",
              "            (tree2): BottleneckX(\n",
              "              (conv1): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
              "              (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (conv3): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (relu): ReLU(inplace=True)\n",
              "            )\n",
              "            (root): Root(\n",
              "              (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (relu): ReLU(inplace=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (downsample): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "        (project): Sequential(\n",
              "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (tree2): Tree(\n",
              "        (tree1): Tree(\n",
              "          (tree1): Tree(\n",
              "            (tree1): BottleneckX(\n",
              "              (conv1): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
              "              (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (conv3): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (relu): ReLU(inplace=True)\n",
              "            )\n",
              "            (tree2): BottleneckX(\n",
              "              (conv1): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
              "              (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (conv3): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (relu): ReLU(inplace=True)\n",
              "            )\n",
              "            (root): Root(\n",
              "              (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (relu): ReLU(inplace=True)\n",
              "            )\n",
              "          )\n",
              "          (tree2): Tree(\n",
              "            (tree1): BottleneckX(\n",
              "              (conv1): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
              "              (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (conv3): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (relu): ReLU(inplace=True)\n",
              "            )\n",
              "            (tree2): BottleneckX(\n",
              "              (conv1): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
              "              (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (conv3): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (relu): ReLU(inplace=True)\n",
              "            )\n",
              "            (root): Root(\n",
              "              (conv): Conv2d(1536, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (relu): ReLU(inplace=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (tree2): Tree(\n",
              "          (tree1): Tree(\n",
              "            (tree1): BottleneckX(\n",
              "              (conv1): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
              "              (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (conv3): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (relu): ReLU(inplace=True)\n",
              "            )\n",
              "            (tree2): BottleneckX(\n",
              "              (conv1): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
              "              (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (conv3): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (relu): ReLU(inplace=True)\n",
              "            )\n",
              "            (root): Root(\n",
              "              (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (relu): ReLU(inplace=True)\n",
              "            )\n",
              "          )\n",
              "          (tree2): Tree(\n",
              "            (tree1): BottleneckX(\n",
              "              (conv1): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
              "              (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (conv3): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (relu): ReLU(inplace=True)\n",
              "            )\n",
              "            (tree2): BottleneckX(\n",
              "              (conv1): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
              "              (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (conv3): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (relu): ReLU(inplace=True)\n",
              "            )\n",
              "            (root): Root(\n",
              "              (conv): Conv2d(2816, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (relu): ReLU(inplace=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (downsample): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (project): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (level5): Tree(\n",
              "      (tree1): BottleneckX(\n",
              "        (conv1): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
              "        (bn2): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (tree2): BottleneckX(\n",
              "        (conv1): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
              "        (bn2): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (root): Root(\n",
              "        (conv): Conv2d(2560, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (downsample): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (project): Sequential(\n",
              "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (avgpool): AvgPool2d(kernel_size=7, stride=7, padding=0)\n",
              "    (fc): Conv2d(1024, 1000, kernel_size=(1, 1), stride=(1, 1))\n",
              "  )\n",
              "  (fc1): Linear(in_features=1000, out_features=11, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "9eLmDPUjLz2-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train( mymodel, trainloader, validloader , device, lr , epoch =100, scheduler = None , model_dir = '/content/drive/MyDrive'  ) : #validloader 는 batch size 1로 하는게 좋을 것 같음.\n",
        "    \n",
        "    print(\"epochs = {} \".format(epoch))\n",
        "  \n",
        "  \n",
        "    optimizer = torch.optim.Adam(mymodel.parameters(),lr =lr  )\n",
        "    loss_function = torch.nn.CrossEntropyLoss().to(device) # 평균값을 뱉어내기 위해서 \n",
        "             \n",
        "    train_losses = []\n",
        "    valid_losses = []\n",
        "    best_acc  = 0 \n",
        "    if (scheduler is not None) :\n",
        "          scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[5*i for i in range(int(epoch/5))], gamma=0.9)\n",
        "    for i in range(epoch) :\n",
        "                mymodel.train()\n",
        "                loss_epoch = 0 \n",
        "                for idx, (batch,label) in enumerate(trainloader) :\n",
        "                    #print(batch.shape)\n",
        "                    #print(label)\n",
        "                    batchsize= batch.shape[0]\n",
        "                    \n",
        "                    batch = batch.to(device)\n",
        "                    optimizer.zero_grad() \n",
        "                    pre = mymodel(batch)\n",
        "                    label  = label.to(device)\n",
        "                \n",
        "                    \n",
        "                    loss = loss_function(pre,label)\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "                    if (scheduler is not None) :\n",
        "                       scheduler.step()\n",
        "                    loss_epoch += loss.detach().item()\n",
        "\n",
        "                    if ((idx+1)%5 == 0 ) :\n",
        "                        print(\"loss of {}th epoch {}th batch : {}\".format(i+1,idx+1,loss.item()))\n",
        "\n",
        "                print(\"-------------------------------------------------------------training epcoh {} is end --------------------\".format(i+1))\n",
        "                print(\"{}th epoch train loss is {}\".format(i+1,loss_epoch/len(trainloader.dataset)))\n",
        "                print(\"Calculating train_accuracy\")\n",
        "               \n",
        "                  \n",
        "                \n",
        "                train_losses.append(loss_epoch/len(trainloader.dataset))\n",
        "\n",
        "\n",
        "                print(\"---------------------validation of after {} epoch \".format(i+1))\n",
        "              \n",
        "                valid_loss = 0\n",
        "                mymodel.eval()\n",
        "                sum =   0 \n",
        "                with torch.no_grad() : \n",
        "                  for batch , label in validloader : \n",
        "                    \n",
        "                     valid_pre = mymodel(batch.to(device)) \n",
        "                     label  = label.to(device)\n",
        "                     loss = loss_function(valid_pre,label)\n",
        "                     pred = torch.argmax(valid_pre , dim=1)\n",
        "                     #print(pred.shape)\n",
        "                     correct =  torch.eq(pred,label.view_as(pred)).cpu().numpy().sum()\n",
        "                     #print(\"correct num is {}\".format(correct))\n",
        "                     sum += correct\n",
        "\n",
        "                     valid_loss += loss.detach().item() \n",
        "\n",
        "\n",
        "                acc = sum/len(validloader.dataset)\n",
        "                if acc > best_acc :  \n",
        "                    best_model = model_dir+'DLA_model.epoch{}.pth'.format(i+1)\n",
        "                    print('update best model to : {}'.format(best_model))\n",
        "                    torch.save(mymodel.state_dict(),model_dir+'DLA_model.epoch{}.pth'.format(i+1))\n",
        "                    best_acc = acc \n",
        "\n",
        "                print(\"{}th epoch vaild loss is {}\".format(i+1,valid_loss/len(validloader.dataset))) \n",
        "                print(\"{}th epoch vaild accuracy is {}\".format(i+1,sum/len(validloader.dataset)))\n",
        "                print(\"----------------------------------------------------------------------------\")\n",
        "                valid_losses.append(valid_loss)         \n",
        "\n",
        "    plt.plot([i+1 for i in range(len(train_losses))],train_losses,c='R')\n",
        "    plt.show()\n",
        "    plt.plot([i+1 for i in range(len(valid_losses))],valid_losses,c = 'B')\n",
        "    plt.show()\n",
        "    print('last best model : {}'.format(best_model))\n",
        "    return best_model\n"
      ],
      "metadata": {
        "id": "W8Bx0ZIvcp6k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "best_model = train(mymodel, trainloader =train_loader , validloader = vali_loader,device = device , lr = 0.0005 ,epoch = 30 , model_dir  = CFG['Directory'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WJIoDXG1PTjl",
        "outputId": "8d46d7d5-7158-4c28-d784-f0255da7aa7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epochs = 30 \n",
            "loss of 1th epoch 5th batch : 1.830891489982605\n",
            "loss of 1th epoch 10th batch : 1.179343342781067\n",
            "loss of 1th epoch 15th batch : 1.2886180877685547\n",
            "loss of 1th epoch 20th batch : 0.996118426322937\n",
            "loss of 1th epoch 25th batch : 0.5240956544876099\n",
            "loss of 1th epoch 30th batch : 0.834893524646759\n",
            "loss of 1th epoch 35th batch : 0.3363645076751709\n",
            "loss of 1th epoch 40th batch : 0.7469643950462341\n",
            "loss of 1th epoch 45th batch : 0.5857841372489929\n",
            "loss of 1th epoch 50th batch : 0.5303481221199036\n",
            "loss of 1th epoch 55th batch : 0.35332685708999634\n",
            "loss of 1th epoch 60th batch : 0.5127279758453369\n",
            "loss of 1th epoch 65th batch : 0.7682280540466309\n",
            "loss of 1th epoch 70th batch : 0.43873488903045654\n",
            "loss of 1th epoch 75th batch : 0.5522652268409729\n",
            "loss of 1th epoch 80th batch : 0.29079991579055786\n",
            "loss of 1th epoch 85th batch : 0.3932594954967499\n",
            "loss of 1th epoch 90th batch : 0.5903043150901794\n",
            "loss of 1th epoch 95th batch : 0.673337996006012\n",
            "loss of 1th epoch 100th batch : 0.3079618215560913\n",
            "loss of 1th epoch 105th batch : 0.5931681394577026\n",
            "-------------------------------------------------------------training epcoh 1 is end --------------------\n",
            "1th epoch train loss is 0.025752813618256775\n",
            "Calculating train_accuracy\n",
            "---------------------validation of after 1 epoch \n",
            "update best model to : /content/drive/MyDrive/Kaggles/Dacon_SignLanguage/DLA_model.epoch1.pth\n",
            "1th epoch vaild loss is 0.01176090265834804\n",
            "1th epoch vaild accuracy is 0.8601398601398601\n",
            "----------------------------------------------------------------------------\n",
            "loss of 2th epoch 5th batch : 0.2500811517238617\n",
            "loss of 2th epoch 10th batch : 0.36713218688964844\n",
            "loss of 2th epoch 15th batch : 0.5719897747039795\n",
            "loss of 2th epoch 20th batch : 0.4781111180782318\n",
            "loss of 2th epoch 25th batch : 0.7840883135795593\n",
            "loss of 2th epoch 30th batch : 0.3829284906387329\n",
            "loss of 2th epoch 35th batch : 0.36088189482688904\n",
            "loss of 2th epoch 40th batch : 0.4189661741256714\n",
            "loss of 2th epoch 45th batch : 0.5048888325691223\n",
            "loss of 2th epoch 50th batch : 0.2467004954814911\n",
            "loss of 2th epoch 55th batch : 0.4635630249977112\n",
            "loss of 2th epoch 60th batch : 0.4341331124305725\n",
            "loss of 2th epoch 65th batch : 0.6120865345001221\n",
            "loss of 2th epoch 70th batch : 0.21042819321155548\n",
            "loss of 2th epoch 75th batch : 1.0013223886489868\n",
            "loss of 2th epoch 80th batch : 0.35901400446891785\n",
            "loss of 2th epoch 85th batch : 0.232965886592865\n",
            "loss of 2th epoch 90th batch : 0.254688560962677\n",
            "loss of 2th epoch 95th batch : 0.2798943817615509\n",
            "loss of 2th epoch 100th batch : 0.6714978218078613\n",
            "loss of 2th epoch 105th batch : 0.19301211833953857\n",
            "-------------------------------------------------------------training epcoh 2 is end --------------------\n",
            "2th epoch train loss is 0.012380358347308872\n",
            "Calculating train_accuracy\n",
            "---------------------validation of after 2 epoch \n",
            "update best model to : /content/drive/MyDrive/Kaggles/Dacon_SignLanguage/DLA_model.epoch2.pth\n",
            "2th epoch vaild loss is 0.0031958340573838818\n",
            "2th epoch vaild accuracy is 0.972027972027972\n",
            "----------------------------------------------------------------------------\n",
            "loss of 3th epoch 5th batch : 0.2132798433303833\n",
            "loss of 3th epoch 10th batch : 0.18595926463603973\n",
            "loss of 3th epoch 15th batch : 0.1569368541240692\n",
            "loss of 3th epoch 20th batch : 0.21376614272594452\n",
            "loss of 3th epoch 25th batch : 0.1924406737089157\n",
            "loss of 3th epoch 30th batch : 0.2230072319507599\n",
            "loss of 3th epoch 35th batch : 0.05477132275700569\n",
            "loss of 3th epoch 40th batch : 0.0780005156993866\n",
            "loss of 3th epoch 45th batch : 0.1469735950231552\n",
            "loss of 3th epoch 50th batch : 0.1975013017654419\n",
            "loss of 3th epoch 55th batch : 0.03218264505267143\n",
            "loss of 3th epoch 60th batch : 0.0061125257052481174\n",
            "loss of 3th epoch 65th batch : 0.1996038258075714\n",
            "loss of 3th epoch 70th batch : 0.1480780392885208\n",
            "loss of 3th epoch 75th batch : 0.04257838428020477\n",
            "loss of 3th epoch 80th batch : 0.2058398276567459\n",
            "loss of 3th epoch 85th batch : 0.4529598653316498\n",
            "loss of 3th epoch 90th batch : 0.02077113278210163\n",
            "loss of 3th epoch 95th batch : 0.3648184835910797\n",
            "loss of 3th epoch 100th batch : 0.3852282762527466\n",
            "loss of 3th epoch 105th batch : 0.1784117966890335\n",
            "-------------------------------------------------------------training epcoh 3 is end --------------------\n",
            "3th epoch train loss is 0.0055342554626280835\n",
            "Calculating train_accuracy\n",
            "---------------------validation of after 3 epoch \n",
            "update best model to : /content/drive/MyDrive/Kaggles/Dacon_SignLanguage/DLA_model.epoch3.pth\n",
            "3th epoch vaild loss is 0.00207808574700689\n",
            "3th epoch vaild accuracy is 0.9790209790209791\n",
            "----------------------------------------------------------------------------\n",
            "loss of 4th epoch 5th batch : 0.15115806460380554\n",
            "loss of 4th epoch 10th batch : 0.043226223438978195\n",
            "loss of 4th epoch 15th batch : 0.0374925397336483\n",
            "loss of 4th epoch 20th batch : 0.021670274436473846\n",
            "loss of 4th epoch 25th batch : 0.1969631463289261\n",
            "loss of 4th epoch 30th batch : 0.1731007695198059\n",
            "loss of 4th epoch 35th batch : 0.13663317263126373\n",
            "loss of 4th epoch 40th batch : 0.1353217214345932\n",
            "loss of 4th epoch 45th batch : 0.04623248055577278\n",
            "loss of 4th epoch 50th batch : 0.2541159689426422\n",
            "loss of 4th epoch 55th batch : 0.1604757159948349\n",
            "loss of 4th epoch 60th batch : 0.18535228073596954\n",
            "loss of 4th epoch 65th batch : 0.02421250008046627\n",
            "loss of 4th epoch 70th batch : 0.12760302424430847\n",
            "loss of 4th epoch 75th batch : 0.10803595930337906\n",
            "loss of 4th epoch 80th batch : 0.07356959581375122\n",
            "loss of 4th epoch 85th batch : 0.2867680788040161\n",
            "loss of 4th epoch 90th batch : 0.04183557257056236\n",
            "loss of 4th epoch 95th batch : 0.005136591847985983\n",
            "loss of 4th epoch 100th batch : 0.02813912369310856\n",
            "loss of 4th epoch 105th batch : 0.09079916775226593\n",
            "-------------------------------------------------------------training epcoh 4 is end --------------------\n",
            "4th epoch train loss is 0.003970954479543288\n",
            "Calculating train_accuracy\n",
            "---------------------validation of after 4 epoch \n",
            "4th epoch vaild loss is 0.0026669466789618636\n",
            "4th epoch vaild accuracy is 0.972027972027972\n",
            "----------------------------------------------------------------------------\n",
            "loss of 5th epoch 5th batch : 0.1822521984577179\n",
            "loss of 5th epoch 10th batch : 0.03685316815972328\n",
            "loss of 5th epoch 15th batch : 0.039898622781038284\n",
            "loss of 5th epoch 20th batch : 0.033392712473869324\n",
            "loss of 5th epoch 25th batch : 0.03486424311995506\n",
            "loss of 5th epoch 30th batch : 0.1660945862531662\n",
            "loss of 5th epoch 35th batch : 0.2224579155445099\n",
            "loss of 5th epoch 40th batch : 0.0213739275932312\n",
            "loss of 5th epoch 45th batch : 0.12346792221069336\n",
            "loss of 5th epoch 50th batch : 0.024366363883018494\n",
            "loss of 5th epoch 55th batch : 0.10327548533678055\n",
            "loss of 5th epoch 60th batch : 0.10323147475719452\n",
            "loss of 5th epoch 65th batch : 0.317841112613678\n",
            "loss of 5th epoch 70th batch : 0.02836943231523037\n",
            "loss of 5th epoch 75th batch : 0.3810882866382599\n",
            "loss of 5th epoch 80th batch : 0.10308121889829636\n",
            "loss of 5th epoch 85th batch : 0.4344058632850647\n",
            "loss of 5th epoch 90th batch : 0.07350550591945648\n",
            "loss of 5th epoch 95th batch : 0.014452338218688965\n",
            "loss of 5th epoch 100th batch : 0.025045931339263916\n",
            "loss of 5th epoch 105th batch : 0.13213208317756653\n",
            "-------------------------------------------------------------training epcoh 5 is end --------------------\n",
            "5th epoch train loss is 0.0031470314648147837\n",
            "Calculating train_accuracy\n",
            "---------------------validation of after 5 epoch \n",
            "update best model to : /content/drive/MyDrive/Kaggles/Dacon_SignLanguage/DLA_model.epoch5.pth\n",
            "5th epoch vaild loss is 0.0012369774469762763\n",
            "5th epoch vaild accuracy is 0.9883449883449883\n",
            "----------------------------------------------------------------------------\n",
            "loss of 6th epoch 5th batch : 0.030180202797055244\n",
            "loss of 6th epoch 10th batch : 0.04803082346916199\n",
            "loss of 6th epoch 15th batch : 0.14610637724399567\n",
            "loss of 6th epoch 20th batch : 0.32423877716064453\n",
            "loss of 6th epoch 25th batch : 0.09435738623142242\n",
            "loss of 6th epoch 30th batch : 0.09822295606136322\n",
            "loss of 6th epoch 35th batch : 0.03519219160079956\n",
            "loss of 6th epoch 40th batch : 0.2551032602787018\n",
            "loss of 6th epoch 45th batch : 0.09629274904727936\n",
            "loss of 6th epoch 50th batch : 0.10228629410266876\n",
            "loss of 6th epoch 55th batch : 0.04113933816552162\n",
            "loss of 6th epoch 60th batch : 0.029509134590625763\n",
            "loss of 6th epoch 65th batch : 0.013100075535476208\n",
            "loss of 6th epoch 70th batch : 0.20347470045089722\n",
            "loss of 6th epoch 75th batch : 0.029917730018496513\n",
            "loss of 6th epoch 80th batch : 0.14411549270153046\n",
            "loss of 6th epoch 85th batch : 0.051972851157188416\n",
            "loss of 6th epoch 90th batch : 0.021584443747997284\n",
            "loss of 6th epoch 95th batch : 0.3403973877429962\n",
            "loss of 6th epoch 100th batch : 0.03280860185623169\n",
            "loss of 6th epoch 105th batch : 0.024058083072304726\n",
            "-------------------------------------------------------------training epcoh 6 is end --------------------\n",
            "6th epoch train loss is 0.0036458877247154695\n",
            "Calculating train_accuracy\n",
            "---------------------validation of after 6 epoch \n",
            "6th epoch vaild loss is 0.004724086167850903\n",
            "6th epoch vaild accuracy is 0.9475524475524476\n",
            "----------------------------------------------------------------------------\n",
            "loss of 7th epoch 5th batch : 0.7086809873580933\n",
            "loss of 7th epoch 10th batch : 0.4564964473247528\n",
            "loss of 7th epoch 15th batch : 0.16985537111759186\n",
            "loss of 7th epoch 20th batch : 0.1722998023033142\n",
            "loss of 7th epoch 25th batch : 0.29179707169532776\n",
            "loss of 7th epoch 30th batch : 0.05177783593535423\n",
            "loss of 7th epoch 35th batch : 0.009201977401971817\n",
            "loss of 7th epoch 40th batch : 0.1290668398141861\n",
            "loss of 7th epoch 45th batch : 0.05149990692734718\n",
            "loss of 7th epoch 50th batch : 0.017192905768752098\n",
            "loss of 7th epoch 55th batch : 0.06566644459962845\n",
            "loss of 7th epoch 60th batch : 0.13780581951141357\n",
            "loss of 7th epoch 65th batch : 0.04711924493312836\n",
            "loss of 7th epoch 70th batch : 0.040636684745550156\n",
            "loss of 7th epoch 75th batch : 0.03588920459151268\n",
            "loss of 7th epoch 80th batch : 0.01087311189621687\n",
            "loss of 7th epoch 85th batch : 0.06842169165611267\n",
            "loss of 7th epoch 90th batch : 0.18613305687904358\n",
            "loss of 7th epoch 95th batch : 0.042282361537218094\n",
            "loss of 7th epoch 100th batch : 0.20385919511318207\n",
            "loss of 7th epoch 105th batch : 0.0895061269402504\n",
            "-------------------------------------------------------------training epcoh 7 is end --------------------\n",
            "7th epoch train loss is 0.0041422375341082784\n",
            "Calculating train_accuracy\n",
            "---------------------validation of after 7 epoch \n",
            "7th epoch vaild loss is 0.009818554376110886\n",
            "7th epoch vaild accuracy is 0.8962703962703963\n",
            "----------------------------------------------------------------------------\n",
            "loss of 8th epoch 5th batch : 0.05383351817727089\n",
            "loss of 8th epoch 10th batch : 0.1758710741996765\n",
            "loss of 8th epoch 15th batch : 0.05685029551386833\n",
            "loss of 8th epoch 20th batch : 0.036512650549411774\n",
            "loss of 8th epoch 25th batch : 0.17775246500968933\n",
            "loss of 8th epoch 30th batch : 0.46439599990844727\n",
            "loss of 8th epoch 35th batch : 0.12211918830871582\n",
            "loss of 8th epoch 40th batch : 0.016075335443019867\n",
            "loss of 8th epoch 45th batch : 0.20439402759075165\n",
            "loss of 8th epoch 50th batch : 0.02691502869129181\n",
            "loss of 8th epoch 55th batch : 0.21763688325881958\n",
            "loss of 8th epoch 60th batch : 0.4669879078865051\n",
            "loss of 8th epoch 65th batch : 0.12693479657173157\n",
            "loss of 8th epoch 70th batch : 0.18548358976840973\n",
            "loss of 8th epoch 75th batch : 0.07443737238645554\n",
            "loss of 8th epoch 80th batch : 0.043970830738544464\n",
            "loss of 8th epoch 85th batch : 0.006146552506834269\n",
            "loss of 8th epoch 90th batch : 0.06081106886267662\n",
            "loss of 8th epoch 95th batch : 0.1245882660150528\n",
            "loss of 8th epoch 100th batch : 0.19292010366916656\n",
            "loss of 8th epoch 105th batch : 0.19813334941864014\n",
            "-------------------------------------------------------------training epcoh 8 is end --------------------\n",
            "8th epoch train loss is 0.004632418718523322\n",
            "Calculating train_accuracy\n",
            "---------------------validation of after 8 epoch \n",
            "8th epoch vaild loss is 0.0019916272359913204\n",
            "8th epoch vaild accuracy is 0.9743589743589743\n",
            "----------------------------------------------------------------------------\n",
            "loss of 9th epoch 5th batch : 0.1964670866727829\n",
            "loss of 9th epoch 10th batch : 0.6080737113952637\n",
            "loss of 9th epoch 15th batch : 0.14838355779647827\n",
            "loss of 9th epoch 20th batch : 0.12742608785629272\n",
            "loss of 9th epoch 25th batch : 0.01929834857583046\n",
            "loss of 9th epoch 30th batch : 0.03222031518816948\n",
            "loss of 9th epoch 35th batch : 0.03342387452721596\n",
            "loss of 9th epoch 40th batch : 0.492948442697525\n",
            "loss of 9th epoch 45th batch : 0.26932018995285034\n",
            "loss of 9th epoch 50th batch : 0.06648686528205872\n",
            "loss of 9th epoch 55th batch : 0.23197941482067108\n",
            "loss of 9th epoch 60th batch : 0.021972980350255966\n",
            "loss of 9th epoch 65th batch : 0.18850083649158478\n",
            "loss of 9th epoch 70th batch : 0.12083017826080322\n",
            "loss of 9th epoch 75th batch : 0.15753617882728577\n",
            "loss of 9th epoch 80th batch : 0.4752754271030426\n",
            "loss of 9th epoch 85th batch : 0.08010470867156982\n",
            "loss of 9th epoch 90th batch : 0.254367858171463\n",
            "loss of 9th epoch 95th batch : 0.03527321666479111\n",
            "loss of 9th epoch 100th batch : 0.19930312037467957\n",
            "loss of 9th epoch 105th batch : 0.08563835173845291\n",
            "-------------------------------------------------------------training epcoh 9 is end --------------------\n",
            "9th epoch train loss is 0.004912500351256016\n",
            "Calculating train_accuracy\n",
            "---------------------validation of after 9 epoch \n",
            "update best model to : /content/drive/MyDrive/Kaggles/Dacon_SignLanguage/DLA_model.epoch9.pth\n",
            "9th epoch vaild loss is 0.0006678855520974854\n",
            "9th epoch vaild accuracy is 0.9953379953379954\n",
            "----------------------------------------------------------------------------\n",
            "loss of 10th epoch 5th batch : 0.06684573739767075\n",
            "loss of 10th epoch 10th batch : 0.03449380025267601\n",
            "loss of 10th epoch 15th batch : 0.4055705964565277\n",
            "loss of 10th epoch 20th batch : 0.0020355721935629845\n",
            "loss of 10th epoch 25th batch : 0.006867169868201017\n",
            "loss of 10th epoch 30th batch : 0.020957717671990395\n",
            "loss of 10th epoch 35th batch : 0.004705177154392004\n",
            "loss of 10th epoch 40th batch : 0.01213266234844923\n",
            "loss of 10th epoch 45th batch : 0.0058149308897554874\n",
            "loss of 10th epoch 50th batch : 0.039185136556625366\n",
            "loss of 10th epoch 55th batch : 0.10345146059989929\n",
            "loss of 10th epoch 60th batch : 0.003918339964002371\n",
            "loss of 10th epoch 65th batch : 0.05453495308756828\n",
            "loss of 10th epoch 70th batch : 0.010643068701028824\n",
            "loss of 10th epoch 75th batch : 0.016827799379825592\n",
            "loss of 10th epoch 80th batch : 0.005102623254060745\n",
            "loss of 10th epoch 85th batch : 0.005718165542930365\n",
            "loss of 10th epoch 90th batch : 0.006467999890446663\n",
            "loss of 10th epoch 95th batch : 0.004054311662912369\n",
            "loss of 10th epoch 100th batch : 0.002487973077222705\n",
            "loss of 10th epoch 105th batch : 0.006807234603911638\n",
            "-------------------------------------------------------------training epcoh 10 is end --------------------\n",
            "10th epoch train loss is 0.0012931232696121214\n",
            "Calculating train_accuracy\n",
            "---------------------validation of after 10 epoch \n",
            "update best model to : /content/drive/MyDrive/Kaggles/Dacon_SignLanguage/DLA_model.epoch10.pth\n",
            "10th epoch vaild loss is 9.328562575239104e-05\n",
            "10th epoch vaild accuracy is 1.0\n",
            "----------------------------------------------------------------------------\n",
            "loss of 11th epoch 5th batch : 0.0022690370678901672\n",
            "loss of 11th epoch 10th batch : 0.0016677484381943941\n",
            "loss of 11th epoch 15th batch : 0.00640311511233449\n",
            "loss of 11th epoch 20th batch : 0.00037293630884960294\n",
            "loss of 11th epoch 25th batch : 0.009779770858585835\n",
            "loss of 11th epoch 30th batch : 0.0017830621218308806\n",
            "loss of 11th epoch 35th batch : 0.01252225786447525\n",
            "loss of 11th epoch 40th batch : 0.025235343724489212\n",
            "loss of 11th epoch 45th batch : 0.0015346810687333345\n",
            "loss of 11th epoch 50th batch : 0.007167085539549589\n",
            "loss of 11th epoch 55th batch : 0.001832054229453206\n",
            "loss of 11th epoch 60th batch : 0.00506889633834362\n",
            "loss of 11th epoch 65th batch : 0.04536323994398117\n",
            "loss of 11th epoch 70th batch : 0.0003547630913089961\n",
            "loss of 11th epoch 75th batch : 0.07676748931407928\n",
            "loss of 11th epoch 80th batch : 0.05215366929769516\n",
            "loss of 11th epoch 85th batch : 0.01743343658745289\n",
            "loss of 11th epoch 90th batch : 0.0047593554481863976\n",
            "loss of 11th epoch 95th batch : 0.003766781184822321\n",
            "loss of 11th epoch 100th batch : 0.0012490773806348443\n",
            "loss of 11th epoch 105th batch : 0.0001975734339794144\n",
            "-------------------------------------------------------------training epcoh 11 is end --------------------\n",
            "11th epoch train loss is 0.0004631080407703755\n",
            "Calculating train_accuracy\n",
            "---------------------validation of after 11 epoch \n",
            "11th epoch vaild loss is 6.433550123163848e-05\n",
            "11th epoch vaild accuracy is 0.9988344988344988\n",
            "----------------------------------------------------------------------------\n",
            "loss of 12th epoch 5th batch : 0.00017976335948333144\n",
            "loss of 12th epoch 10th batch : 0.0016842938493937254\n",
            "loss of 12th epoch 15th batch : 0.007867657579481602\n",
            "loss of 12th epoch 20th batch : 0.0012133948039263487\n",
            "loss of 12th epoch 25th batch : 0.0007981022354215384\n",
            "loss of 12th epoch 30th batch : 0.000355725409463048\n",
            "loss of 12th epoch 35th batch : 0.003879689611494541\n",
            "loss of 12th epoch 40th batch : 0.006216287612915039\n",
            "loss of 12th epoch 45th batch : 0.0009007579064927995\n",
            "loss of 12th epoch 50th batch : 0.001559562049806118\n",
            "loss of 12th epoch 55th batch : 0.2460806667804718\n",
            "loss of 12th epoch 60th batch : 0.000928470166400075\n",
            "loss of 12th epoch 65th batch : 0.06592859327793121\n",
            "loss of 12th epoch 70th batch : 0.019803011789917946\n",
            "loss of 12th epoch 75th batch : 0.07006136327981949\n",
            "loss of 12th epoch 80th batch : 0.001975076273083687\n",
            "loss of 12th epoch 85th batch : 0.06563753634691238\n",
            "loss of 12th epoch 90th batch : 0.0016311367508023977\n",
            "loss of 12th epoch 95th batch : 0.0450131818652153\n",
            "loss of 12th epoch 100th batch : 0.025391889736056328\n",
            "loss of 12th epoch 105th batch : 0.10385653376579285\n",
            "-------------------------------------------------------------training epcoh 12 is end --------------------\n",
            "12th epoch train loss is 0.0007263062204395288\n",
            "Calculating train_accuracy\n",
            "---------------------validation of after 12 epoch \n",
            "12th epoch vaild loss is 0.00020513641107216177\n",
            "12th epoch vaild accuracy is 0.9965034965034965\n",
            "----------------------------------------------------------------------------\n",
            "loss of 13th epoch 5th batch : 0.0010889641707763076\n",
            "loss of 13th epoch 10th batch : 0.2991863787174225\n",
            "loss of 13th epoch 15th batch : 0.025729434564709663\n",
            "loss of 13th epoch 20th batch : 0.010718106292188168\n",
            "loss of 13th epoch 25th batch : 0.018437664955854416\n",
            "loss of 13th epoch 30th batch : 0.00810134969651699\n",
            "loss of 13th epoch 35th batch : 0.021422164514660835\n",
            "loss of 13th epoch 40th batch : 0.0017533235950395465\n",
            "loss of 13th epoch 45th batch : 0.007019842509180307\n",
            "loss of 13th epoch 50th batch : 0.0014351176796481013\n",
            "loss of 13th epoch 55th batch : 0.0013073004083707929\n",
            "loss of 13th epoch 60th batch : 0.046529047191143036\n",
            "loss of 13th epoch 65th batch : 0.0006977542070671916\n",
            "loss of 13th epoch 70th batch : 0.13238674402236938\n",
            "loss of 13th epoch 75th batch : 0.001819048309698701\n",
            "loss of 13th epoch 80th batch : 0.16469381749629974\n",
            "loss of 13th epoch 85th batch : 0.16650962829589844\n",
            "loss of 13th epoch 90th batch : 0.0006868913769721985\n",
            "loss of 13th epoch 95th batch : 0.030116556212306023\n",
            "loss of 13th epoch 100th batch : 0.04612929746508598\n",
            "loss of 13th epoch 105th batch : 0.013015199452638626\n",
            "-------------------------------------------------------------training epcoh 13 is end --------------------\n",
            "13th epoch train loss is 0.001720302915611369\n",
            "Calculating train_accuracy\n",
            "---------------------validation of after 13 epoch \n",
            "13th epoch vaild loss is 0.00781601896435717\n",
            "13th epoch vaild accuracy is 0.9382284382284383\n",
            "----------------------------------------------------------------------------\n",
            "loss of 14th epoch 5th batch : 0.5831640958786011\n",
            "loss of 14th epoch 10th batch : 0.1453259438276291\n",
            "loss of 14th epoch 15th batch : 0.11780721694231033\n",
            "loss of 14th epoch 20th batch : 0.10791846364736557\n",
            "loss of 14th epoch 25th batch : 0.03543674573302269\n",
            "loss of 14th epoch 30th batch : 0.05330658704042435\n",
            "loss of 14th epoch 35th batch : 0.08417639136314392\n",
            "loss of 14th epoch 40th batch : 0.010978959500789642\n",
            "loss of 14th epoch 45th batch : 0.3027093708515167\n",
            "loss of 14th epoch 50th batch : 0.13851389288902283\n",
            "loss of 14th epoch 55th batch : 0.04545142874121666\n",
            "loss of 14th epoch 60th batch : 0.12841551005840302\n",
            "loss of 14th epoch 65th batch : 0.008726557716727257\n",
            "loss of 14th epoch 70th batch : 0.004344576504081488\n",
            "loss of 14th epoch 75th batch : 0.02085244469344616\n",
            "loss of 14th epoch 80th batch : 0.04347894340753555\n",
            "loss of 14th epoch 85th batch : 0.05533672869205475\n",
            "loss of 14th epoch 90th batch : 0.027267061173915863\n",
            "loss of 14th epoch 95th batch : 0.001674769795499742\n",
            "loss of 14th epoch 100th batch : 0.0038010352291166782\n",
            "loss of 14th epoch 105th batch : 0.016614701598882675\n",
            "-------------------------------------------------------------training epcoh 14 is end --------------------\n",
            "14th epoch train loss is 0.002228168729304782\n",
            "Calculating train_accuracy\n",
            "---------------------validation of after 14 epoch \n",
            "14th epoch vaild loss is 0.0008235144495257417\n",
            "14th epoch vaild accuracy is 0.9906759906759907\n",
            "----------------------------------------------------------------------------\n",
            "loss of 15th epoch 5th batch : 0.001554169342853129\n",
            "loss of 15th epoch 10th batch : 0.03489622473716736\n",
            "loss of 15th epoch 15th batch : 0.010642819106578827\n",
            "loss of 15th epoch 20th batch : 0.009098484180867672\n",
            "loss of 15th epoch 25th batch : 0.015954939648509026\n",
            "loss of 15th epoch 30th batch : 0.045104436576366425\n",
            "loss of 15th epoch 35th batch : 0.005310723092406988\n",
            "loss of 15th epoch 40th batch : 0.0030572216492146254\n",
            "loss of 15th epoch 45th batch : 0.0027453273069113493\n",
            "loss of 15th epoch 50th batch : 0.00020567209867294878\n",
            "loss of 15th epoch 55th batch : 0.002163819270208478\n",
            "loss of 15th epoch 60th batch : 0.04369746148586273\n",
            "loss of 15th epoch 65th batch : 0.00039059651317074895\n",
            "loss of 15th epoch 70th batch : 0.019138194620609283\n",
            "loss of 15th epoch 75th batch : 0.0005848540458828211\n",
            "loss of 15th epoch 80th batch : 0.0005602503661066294\n",
            "loss of 15th epoch 85th batch : 0.0005117793334648013\n",
            "loss of 15th epoch 90th batch : 0.006050668191164732\n",
            "loss of 15th epoch 95th batch : 0.07445316016674042\n",
            "loss of 15th epoch 100th batch : 0.0048070610500872135\n",
            "loss of 15th epoch 105th batch : 0.00971253402531147\n",
            "-------------------------------------------------------------training epcoh 15 is end --------------------\n",
            "15th epoch train loss is 0.0007498704220151943\n",
            "Calculating train_accuracy\n",
            "---------------------validation of after 15 epoch \n",
            "15th epoch vaild loss is 0.0014545580230494266\n",
            "15th epoch vaild accuracy is 0.9836829836829837\n",
            "----------------------------------------------------------------------------\n",
            "loss of 16th epoch 5th batch : 0.007143220864236355\n",
            "loss of 16th epoch 10th batch : 0.0028457592707127333\n",
            "loss of 16th epoch 15th batch : 0.0042402371764183044\n",
            "loss of 16th epoch 20th batch : 0.0017404577229171991\n",
            "loss of 16th epoch 25th batch : 0.1826995611190796\n",
            "loss of 16th epoch 30th batch : 0.17134009301662445\n",
            "loss of 16th epoch 35th batch : 0.04397604614496231\n",
            "loss of 16th epoch 40th batch : 0.01257074810564518\n",
            "loss of 16th epoch 45th batch : 0.0012869127094745636\n",
            "loss of 16th epoch 50th batch : 0.4407278895378113\n",
            "loss of 16th epoch 55th batch : 0.05651909112930298\n",
            "loss of 16th epoch 60th batch : 0.11994362622499466\n",
            "loss of 16th epoch 65th batch : 0.0402260422706604\n",
            "loss of 16th epoch 70th batch : 0.1834849864244461\n",
            "loss of 16th epoch 75th batch : 0.5427193641662598\n",
            "loss of 16th epoch 80th batch : 0.008003832772374153\n",
            "loss of 16th epoch 85th batch : 0.020396966487169266\n",
            "loss of 16th epoch 90th batch : 0.015972033143043518\n",
            "loss of 16th epoch 95th batch : 0.16372233629226685\n",
            "loss of 16th epoch 100th batch : 0.023808402940630913\n",
            "loss of 16th epoch 105th batch : 0.09035088121891022\n",
            "-------------------------------------------------------------training epcoh 16 is end --------------------\n",
            "16th epoch train loss is 0.0041936463204219\n",
            "Calculating train_accuracy\n",
            "---------------------validation of after 16 epoch \n",
            "16th epoch vaild loss is 0.0004460344758342804\n",
            "16th epoch vaild accuracy is 0.9953379953379954\n",
            "----------------------------------------------------------------------------\n",
            "loss of 17th epoch 5th batch : 0.1408979892730713\n",
            "loss of 17th epoch 10th batch : 0.18685093522071838\n",
            "loss of 17th epoch 15th batch : 0.02489008754491806\n",
            "loss of 17th epoch 20th batch : 0.011204343289136887\n",
            "loss of 17th epoch 25th batch : 0.3624759912490845\n",
            "loss of 17th epoch 30th batch : 0.07934655249118805\n",
            "loss of 17th epoch 35th batch : 0.34371984004974365\n",
            "loss of 17th epoch 40th batch : 0.1725403517484665\n",
            "loss of 17th epoch 45th batch : 0.2753537893295288\n",
            "loss of 17th epoch 50th batch : 0.012547029182314873\n",
            "loss of 17th epoch 55th batch : 0.381218284368515\n",
            "loss of 17th epoch 60th batch : 0.014044183306396008\n",
            "loss of 17th epoch 65th batch : 0.25102266669273376\n",
            "loss of 17th epoch 70th batch : 0.054409418255090714\n",
            "loss of 17th epoch 75th batch : 0.1326874941587448\n",
            "loss of 17th epoch 80th batch : 0.0055577573366463184\n",
            "loss of 17th epoch 85th batch : 0.0832398384809494\n",
            "loss of 17th epoch 90th batch : 0.03994413837790489\n",
            "loss of 17th epoch 95th batch : 0.16111019253730774\n",
            "loss of 17th epoch 100th batch : 0.030487967655062675\n",
            "loss of 17th epoch 105th batch : 0.016625573858618736\n",
            "-------------------------------------------------------------training epcoh 17 is end --------------------\n",
            "17th epoch train loss is 0.003374628583661287\n",
            "Calculating train_accuracy\n",
            "---------------------validation of after 17 epoch \n",
            "17th epoch vaild loss is 0.00018435887934581434\n",
            "17th epoch vaild accuracy is 0.9976689976689976\n",
            "----------------------------------------------------------------------------\n",
            "loss of 18th epoch 5th batch : 0.014004334807395935\n",
            "loss of 18th epoch 10th batch : 0.005294745787978172\n",
            "loss of 18th epoch 15th batch : 0.006860512308776379\n",
            "loss of 18th epoch 20th batch : 0.022605866193771362\n",
            "loss of 18th epoch 25th batch : 0.0026837617624551058\n",
            "loss of 18th epoch 30th batch : 0.048499200493097305\n",
            "loss of 18th epoch 35th batch : 0.20393557846546173\n",
            "loss of 18th epoch 40th batch : 0.0006982508348301053\n",
            "loss of 18th epoch 45th batch : 0.0029469463042914867\n",
            "loss of 18th epoch 50th batch : 0.019145304337143898\n",
            "loss of 18th epoch 55th batch : 0.010721680708229542\n",
            "loss of 18th epoch 60th batch : 0.0027099561411887407\n",
            "loss of 18th epoch 65th batch : 0.004488152917474508\n",
            "loss of 18th epoch 70th batch : 0.0006398828118108213\n",
            "loss of 18th epoch 75th batch : 0.12561094760894775\n",
            "loss of 18th epoch 80th batch : 0.008483028039336205\n",
            "loss of 18th epoch 85th batch : 0.0016080121276900172\n",
            "loss of 18th epoch 90th batch : 0.0015350005123764277\n",
            "loss of 18th epoch 95th batch : 0.012706195935606956\n",
            "loss of 18th epoch 100th batch : 0.009114119224250317\n",
            "loss of 18th epoch 105th batch : 0.11467646062374115\n",
            "-------------------------------------------------------------training epcoh 18 is end --------------------\n",
            "18th epoch train loss is 0.0013588010805567683\n",
            "Calculating train_accuracy\n",
            "---------------------validation of after 18 epoch \n",
            "18th epoch vaild loss is 0.0005903154977115353\n",
            "18th epoch vaild accuracy is 0.9953379953379954\n",
            "----------------------------------------------------------------------------\n",
            "loss of 19th epoch 5th batch : 0.1302742213010788\n",
            "loss of 19th epoch 10th batch : 0.13381998240947723\n",
            "loss of 19th epoch 15th batch : 0.20757830142974854\n",
            "loss of 19th epoch 20th batch : 0.10919696092605591\n",
            "loss of 19th epoch 25th batch : 0.0013909118715673685\n",
            "loss of 19th epoch 30th batch : 0.4200112819671631\n",
            "loss of 19th epoch 35th batch : 0.025186812505126\n",
            "loss of 19th epoch 40th batch : 0.013498453423380852\n",
            "loss of 19th epoch 45th batch : 0.0025530699640512466\n",
            "loss of 19th epoch 50th batch : 0.028209347277879715\n",
            "loss of 19th epoch 55th batch : 0.0016440186882391572\n",
            "loss of 19th epoch 60th batch : 0.03448445722460747\n",
            "loss of 19th epoch 65th batch : 0.0012699788203462958\n",
            "loss of 19th epoch 70th batch : 0.004572256002575159\n",
            "loss of 19th epoch 75th batch : 0.031291767954826355\n",
            "loss of 19th epoch 80th batch : 0.012686680071055889\n",
            "loss of 19th epoch 85th batch : 0.020267078652977943\n",
            "loss of 19th epoch 90th batch : 0.02649950236082077\n",
            "loss of 19th epoch 95th batch : 0.002924842992797494\n",
            "loss of 19th epoch 100th batch : 0.0016077125910669565\n",
            "loss of 19th epoch 105th batch : 0.041827242821455\n",
            "-------------------------------------------------------------training epcoh 19 is end --------------------\n",
            "19th epoch train loss is 0.002029644127042111\n",
            "Calculating train_accuracy\n",
            "---------------------validation of after 19 epoch \n",
            "19th epoch vaild loss is 0.0012976683820473\n",
            "19th epoch vaild accuracy is 0.9871794871794872\n",
            "----------------------------------------------------------------------------\n",
            "loss of 20th epoch 5th batch : 0.0014863706892356277\n",
            "loss of 20th epoch 10th batch : 0.0018163021886721253\n",
            "loss of 20th epoch 15th batch : 0.0017962976126000285\n",
            "loss of 20th epoch 20th batch : 0.0077765206806361675\n",
            "loss of 20th epoch 25th batch : 0.0004183092969469726\n",
            "loss of 20th epoch 30th batch : 0.00032073166221380234\n",
            "loss of 20th epoch 35th batch : 0.0001974544138647616\n",
            "loss of 20th epoch 40th batch : 0.06449462473392487\n",
            "loss of 20th epoch 45th batch : 0.013399101793766022\n",
            "loss of 20th epoch 50th batch : 0.013737056404352188\n",
            "loss of 20th epoch 55th batch : 0.00099159253295511\n",
            "loss of 20th epoch 60th batch : 0.007527194917201996\n",
            "loss of 20th epoch 65th batch : 0.0020935945212841034\n",
            "loss of 20th epoch 70th batch : 0.0065689715556800365\n",
            "loss of 20th epoch 75th batch : 0.0004967877175658941\n",
            "loss of 20th epoch 80th batch : 0.0019193016923964024\n",
            "loss of 20th epoch 85th batch : 0.0010787065839394927\n",
            "loss of 20th epoch 90th batch : 0.0018437227699905634\n",
            "loss of 20th epoch 95th batch : 0.00251218699850142\n",
            "loss of 20th epoch 100th batch : 0.0007391776307485998\n",
            "loss of 20th epoch 105th batch : 0.0012491879751905799\n",
            "-------------------------------------------------------------training epcoh 20 is end --------------------\n",
            "20th epoch train loss is 0.00030532649844646886\n",
            "Calculating train_accuracy\n",
            "---------------------validation of after 20 epoch \n",
            "20th epoch vaild loss is 7.318158585992441e-06\n",
            "20th epoch vaild accuracy is 1.0\n",
            "----------------------------------------------------------------------------\n",
            "loss of 21th epoch 5th batch : 0.0003173207805957645\n",
            "loss of 21th epoch 10th batch : 0.0008539558621123433\n",
            "loss of 21th epoch 15th batch : 0.0015457046683877707\n",
            "loss of 21th epoch 20th batch : 0.0005638013826683164\n",
            "loss of 21th epoch 25th batch : 0.004646307323127985\n",
            "loss of 21th epoch 30th batch : 0.00017785582167562097\n",
            "loss of 21th epoch 35th batch : 0.0013626916334033012\n",
            "loss of 21th epoch 40th batch : 0.0001563907862873748\n",
            "loss of 21th epoch 45th batch : 4.173996421741322e-05\n",
            "loss of 21th epoch 50th batch : 0.0009288188302889466\n",
            "loss of 21th epoch 55th batch : 0.0003710851015057415\n",
            "loss of 21th epoch 60th batch : 0.0001422709465259686\n",
            "loss of 21th epoch 65th batch : 0.0003297368239145726\n",
            "loss of 21th epoch 70th batch : 0.00010221773845842108\n",
            "loss of 21th epoch 75th batch : 0.00017304046195931733\n",
            "loss of 21th epoch 80th batch : 0.00022255668591242284\n",
            "loss of 21th epoch 85th batch : 0.0002422015240881592\n",
            "loss of 21th epoch 90th batch : 0.00017422031669411808\n",
            "loss of 21th epoch 95th batch : 0.0013170427409932017\n",
            "loss of 21th epoch 100th batch : 0.0002924949221778661\n",
            "loss of 21th epoch 105th batch : 0.0008385110413655639\n",
            "-------------------------------------------------------------training epcoh 21 is end --------------------\n",
            "21th epoch train loss is 2.8033311414039295e-05\n",
            "Calculating train_accuracy\n",
            "---------------------validation of after 21 epoch \n",
            "21th epoch vaild loss is 2.029235300392482e-06\n",
            "21th epoch vaild accuracy is 1.0\n",
            "----------------------------------------------------------------------------\n",
            "loss of 22th epoch 5th batch : 5.371657243813388e-05\n",
            "loss of 22th epoch 10th batch : 0.00023645878536626697\n",
            "loss of 22th epoch 15th batch : 0.0019787291530519724\n",
            "loss of 22th epoch 20th batch : 0.00028657441725954413\n",
            "loss of 22th epoch 25th batch : 0.0002509250189177692\n",
            "loss of 22th epoch 30th batch : 6.663621752522886e-05\n",
            "loss of 22th epoch 35th batch : 0.00026011664886027575\n",
            "loss of 22th epoch 40th batch : 0.0001633878273423761\n",
            "loss of 22th epoch 45th batch : 0.0001185212895506993\n",
            "loss of 22th epoch 50th batch : 0.0003645234100986272\n",
            "loss of 22th epoch 55th batch : 0.00030582110048271716\n",
            "loss of 22th epoch 60th batch : 0.00031933459104038775\n",
            "loss of 22th epoch 65th batch : 0.0008157478296197951\n",
            "loss of 22th epoch 70th batch : 3.456690683378838e-05\n",
            "loss of 22th epoch 75th batch : 0.003543721977621317\n",
            "loss of 22th epoch 80th batch : 0.0021742170210927725\n",
            "loss of 22th epoch 85th batch : 9.385035082232207e-05\n",
            "loss of 22th epoch 90th batch : 0.0006324384012259543\n",
            "loss of 22th epoch 95th batch : 9.933225373970345e-05\n",
            "loss of 22th epoch 100th batch : 0.00023921788670122623\n",
            "loss of 22th epoch 105th batch : 0.0005805270629934967\n",
            "-------------------------------------------------------------training epcoh 22 is end --------------------\n",
            "22th epoch train loss is 2.268561263277695e-05\n",
            "Calculating train_accuracy\n",
            "---------------------validation of after 22 epoch \n",
            "22th epoch vaild loss is 2.3685597646644984e-06\n",
            "22th epoch vaild accuracy is 1.0\n",
            "----------------------------------------------------------------------------\n",
            "loss of 23th epoch 5th batch : 0.00037266232538968325\n",
            "loss of 23th epoch 10th batch : 0.00010341397864976898\n",
            "loss of 23th epoch 15th batch : 1.6811065506772138e-05\n",
            "loss of 23th epoch 20th batch : 0.003842781763523817\n",
            "loss of 23th epoch 25th batch : 1.6252772184088826e-05\n",
            "loss of 23th epoch 30th batch : 0.000350670306943357\n",
            "loss of 23th epoch 35th batch : 0.0003201549407094717\n",
            "loss of 23th epoch 40th batch : 0.000618342834059149\n",
            "loss of 23th epoch 45th batch : 0.0010894769802689552\n",
            "loss of 23th epoch 50th batch : 0.000246007606619969\n",
            "loss of 23th epoch 55th batch : 0.00023576841340400279\n",
            "loss of 23th epoch 60th batch : 0.0012601581402122974\n",
            "loss of 23th epoch 65th batch : 6.711432797601447e-05\n",
            "loss of 23th epoch 70th batch : 2.8961329007870518e-05\n",
            "loss of 23th epoch 75th batch : 0.0007146744173951447\n",
            "loss of 23th epoch 80th batch : 0.00026541101397015154\n",
            "loss of 23th epoch 85th batch : 6.532377301482484e-05\n",
            "loss of 23th epoch 90th batch : 2.24589130084496e-05\n",
            "loss of 23th epoch 95th batch : 0.00011035421630367637\n",
            "loss of 23th epoch 100th batch : 0.00010156429198104888\n",
            "loss of 23th epoch 105th batch : 0.00038039986975491047\n",
            "-------------------------------------------------------------training epcoh 23 is end --------------------\n",
            "23th epoch train loss is 1.6902993400060415e-05\n",
            "Calculating train_accuracy\n",
            "---------------------validation of after 23 epoch \n",
            "23th epoch vaild loss is 1.4706152637329136e-06\n",
            "23th epoch vaild accuracy is 1.0\n",
            "----------------------------------------------------------------------------\n",
            "loss of 24th epoch 5th batch : 0.0003946828655898571\n",
            "loss of 24th epoch 10th batch : 8.059285755734891e-05\n",
            "loss of 24th epoch 15th batch : 0.00012630072887986898\n",
            "loss of 24th epoch 20th batch : 7.248977635754272e-05\n",
            "loss of 24th epoch 25th batch : 6.978066812735051e-05\n",
            "loss of 24th epoch 30th batch : 3.8228274206630886e-05\n",
            "loss of 24th epoch 35th batch : 0.00017582564032636583\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-79-deb3a67d8f89>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmymodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainloader\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mtrain_loader\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mvalidloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvali_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0005\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mmodel_dir\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mCFG\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Directory'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-78-87d3b097a02e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(mymodel, trainloader, validloader, device, lr, epoch, scheduler, model_dir)\u001b[0m\n\u001b[1;32m     28\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpre\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m                     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscheduler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                        \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    151\u001b[0m                    \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m                    \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m                    maximize=group['maximize'])\n\u001b[0m\u001b[1;32m    154\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/_functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0;31m# Maintains the maximum of all 2nd moment running avg. till now\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 가장 좋은 걸로 submission 한번 해보기  - 일단 시험전에는 여기서 끝내고 다른 task에 transformer 모델을 공부하고 적용해보는걸로 bert gpt-3 비지도학습 등등해보자.\n",
        "mymodel.load_state_dict(torch.load('/content/drive/MyDrive/Kaggles/Dacon_SignLanguage/DLA_model.epoch10.pth'))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_sfSfOZ8EJEl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23be0b9e-8730-43b7-b504-f1d681131fb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_imgs , test_labels = augmentation(test_img_path,None,train = False) \n",
        "test_dataset = CustomDataset(test_imgs,None, mode = 'test')\n",
        "test_loader = DataLoader(test_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=False, num_workers=4)"
      ],
      "metadata": {
        "id": "CAuGqQc9DZJp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm\n",
        "def predict(model, test_loader, device):\n",
        "    model.eval()\n",
        "    model_pred = []\n",
        "    with torch.no_grad():\n",
        "        for img in tqdm(iter(test_loader)):\n",
        "            img = img.to(device)\n",
        "\n",
        "            pred_logit = model(img)\n",
        "            pred_logit = pred_logit.argmax(dim=1, keepdim=True).squeeze(1)\n",
        "\n",
        "            model_pred.extend(pred_logit.tolist())\n",
        "    return model_pred"
      ],
      "metadata": {
        "id": "IrHXOWdnEu_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = predict(mymodel, test_loader, device)\n",
        "preds[0:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "a2c5a8ae217a44b3bd6f4e51eb6c1418",
            "d85dc8f1e3064466a961013cecda5dd1",
            "347315eff05c4f6388e8c56e1dbb1605",
            "71fe477487fc49728938bae5e8d17937",
            "58d6e2ff11884700a1fb0e2ca23a3f5f",
            "0d7866ccff634aa6a1b6a26ac49678c3",
            "0b002512c51b4477a5749bfea636d727",
            "e262edb53d944380a3e9d22803b1f426",
            "14b7c1b4faae45a3919c7c8e7e360628",
            "771289b4cff147a395472ed67de5c6fd",
            "32e44cd894894f2b9b6f802195025341"
          ]
        },
        "id": "QF6BcqQbFDiF",
        "outputId": "d4b4cff4-80e4-4489-a620-7b209a6e684b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/7 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a2c5a8ae217a44b3bd6f4e51eb6c1418"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 1, 6, 8]"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "submission = pd.read_csv(datadir +'sample_submission.csv')\n",
        "submission['label'] = preds\n",
        "submission['label'][submission['label'] == 10] = '10-1' ## label : 10 -> '10-1'\n",
        "submission['label'][submission['label'] == 0] = '10-2' ## Label : 0 -> '10-2'\n",
        "submission['label'] = submission['label'].apply(lambda x : str(x)) ## Dtype : int -> object"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4UvU8sfFH1Z",
        "outputId": "4fe09ce7-0f7a-4a83-d53f-27a42494870d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "submission.head()\n",
        "submission.to_csv(datadir + 'submit_non_valid2.csv', index=False)"
      ],
      "metadata": {
        "id": "nDwmp6MXFj3p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell \n",
        "\n",
        "cd /content/drive/MyDrive/Kaggles/Dacon_SignLanguage/\n",
        "\n",
        "git config --global user.email galaxy0612@snu.ac.kr\n",
        "git config --global user.name Orcas \n",
        "\n",
        "git add .\n",
        "git commit -m \"Dacon novice signlanguage classification\"\n",
        "\n",
        "git remote add origin https://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@github.com/username/reponame.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 614
        },
        "id": "Eymx5-pcB7W6",
        "outputId": "c02eab82-e3de-4ac9-a87b-7901886910d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: not a git repository (or any parent up to mount point /content)\n",
            "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n",
            "fatal: not a git repository (or any parent up to mount point /content)\n",
            "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n",
            "fatal: not a git repository (or any parent up to mount point /content)\n",
            "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "CalledProcessError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-87-cb95a993aa94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'shell'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\ncd /content/drive/MyDrive/Kaggles/Dacon_SignLanguage/\\n\\ngit config --global user.email galaxy0612@snu.ac.kr\\ngit config --global user.name Orcas \\n\\ngit add .\\ngit commit -m \"Dacon novice signlanguage classification\"\\n\\ngit remote add origin https://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@github.com/username/reponame.git'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_shell_cell_magic\u001b[0;34m(args, cmd)\u001b[0m\n\u001b[1;32m    111\u001b[0m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclear_streamed_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparsed_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_errors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_returncode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36mcheck_returncode\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m       raise subprocess.CalledProcessError(\n\u001b[0;32m--> 139\u001b[0;31m           returncode=self.returncode, cmd=self.args, output=self.output)\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_repr_pretty_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=unused-argument\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mCalledProcessError\u001b[0m: Command '\ncd /content/drive/MyDrive/Kaggles/Dacon_SignLanguage/\n\ngit config --global user.email galaxy0612@snu.ac.kr\ngit config --global user.name Orcas \n\ngit add .\ngit commit -m \"Dacon novice signlanguage classification\"\n\ngit remote add origin https://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@github.com/username/reponame.git' returned non-zero exit status 128."
          ]
        }
      ]
    }
  ]
}